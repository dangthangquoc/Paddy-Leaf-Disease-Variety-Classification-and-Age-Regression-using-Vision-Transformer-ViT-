{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3aa4482",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1865b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow logging\n",
    "tf.get_logger().setLevel('ERROR')  # Suppress TensorFlow logging\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "np.random.seed(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801720e1",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4604449",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "batch_size = 32\n",
    "image_size = 72\n",
    "patch_size = 6\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]\n",
    "input_shape = (256, 256, 3)\n",
    "num_classes = 10  # Number of classes for disease classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab75e8f",
   "metadata": {},
   "source": [
    "# Custom layers for Importing Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d56a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layers needed for the models\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super(Patches, self).__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        patch_size = config.pop(\"patch_size\")\n",
    "        return cls(patch_size=patch_size, **config)\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super(PatchEncoder, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\": self.projection_dim\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        num_patches = config.pop(\"num_patches\")\n",
    "        projection_dim = config.pop(\"projection_dim\")\n",
    "        return cls(num_patches=num_patches, projection_dim=projection_dim, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2baf1",
   "metadata": {},
   "source": [
    "# Define Model Architecture for Importing Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11509be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for the ViT model\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851b1146",
   "metadata": {},
   "source": [
    "##  ViT Model for Disease Classification (Task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6151835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_disease_classifier():\n",
    "    # Create a standalone normalization layer\n",
    "    normalization = layers.Normalization()\n",
    "    \n",
    "    # Create data augmentation separately\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.Resizing(image_size, image_size),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(factor=0.02),\n",
    "            layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Normalize data\n",
    "    normalized = normalization(inputs)\n",
    "\n",
    "    # Augment data\n",
    "    augmented = data_augmentation(normalized)\n",
    "\n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "\n",
    "    # Encode patches\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs\n",
    "    logits = layers.Dense(num_classes, activation='softmax', name='disease_output')(features)\n",
    "    # Create the Keras model\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edacd751",
   "metadata": {},
   "source": [
    "## ViT Model for Variety Classification (Task 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10daacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_variety_classifier():\n",
    "    # Create a standalone normalization layer\n",
    "    normalization = layers.Normalization()\n",
    "    \n",
    "    # Create data augmentation separately\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.Resizing(image_size, image_size),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(factor=0.02),\n",
    "            layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Normalize data\n",
    "    normalized = normalization(inputs)\n",
    "\n",
    "    # Augment data\n",
    "    augmented = data_augmentation(normalized)\n",
    "\n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs\n",
    "    logits = layers.Dense(num_classes, activation='softmax', name='variety_output')(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a80237",
   "metadata": {},
   "source": [
    "## Function to create the ViT model for Age Regression (Task 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd9b8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_regressor():\n",
    "    # Create data augmentation\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.Normalization(),\n",
    "            layers.Resizing(image_size, image_size),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(factor=0.02),\n",
    "            layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Augment data\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    \n",
    "    # Encode patches\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        \n",
    "        # Create a multi-head attention layer\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        \n",
    "        # Skip connection 1\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        \n",
    "        # Layer normalization 2\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        \n",
    "        # MLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        \n",
    "        # Skip connection 2\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    \n",
    "    # Add MLP\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    \n",
    "    # Output layer for regression (single neuron for age)\n",
    "    output = layers.Dense(1, activation='linear')(features)\n",
    "    \n",
    "    # Create the Keras model\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03732a1d",
   "metadata": {},
   "source": [
    "## Function to preprocess image for disease and variety models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f5c8359",
   "metadata": {},
   "outputs": [],
   "source": [
    " def preprocess_image(image_path):\n",
    "    \"\"\"Process image for model prediction\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = img.resize((img_width, img_height))\n",
    "        img_array = np.array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to preprocess image for age model\n",
    "def preprocess_age_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = img.resize((img_width, img_height))\n",
    "        img_array = np.array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2daa92",
   "metadata": {},
   "source": [
    "# ModelHandler class to manage model loading and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e453c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddyModelHandler:\n",
    "    def __init__(self):\n",
    "        self.home_path = os.getcwd()\n",
    "        self.models_path = os.path.join(self.home_path, 'paddy_models')\n",
    "        os.makedirs(self.models_path, exist_ok=True)\n",
    "        \n",
    "        # Define paths for ensemble model storage\n",
    "        self.kfold_models_path = os.path.join(self.models_path, 'kfold_models')\n",
    "        os.makedirs(self.kfold_models_path, exist_ok=True)\n",
    "        \n",
    "        print(\"Loading encoders and models...\")\n",
    "        # Load label encoders\n",
    "        self.load_encoders()\n",
    "        \n",
    "        # Load models\n",
    "        self.load_models()\n",
    "        \n",
    "    def load_encoders(self):\n",
    "        \"\"\"Load label encoders for predictions\"\"\"\n",
    "        try:\n",
    "            # Try to load variety encoder\n",
    "            variety_encoder_path = 'variety_label_encoder.joblib'\n",
    "            if os.path.exists(variety_encoder_path):\n",
    "                self.variety_encoder = joblib.load(variety_encoder_path)\n",
    "                print(f\"Loaded variety encoder with {len(self.variety_encoder.classes_)} classes\")\n",
    "                self.num_varieties = len(self.variety_encoder.classes_)\n",
    "            else:\n",
    "                # Create fallback encoder\n",
    "                from sklearn.preprocessing import LabelEncoder\n",
    "                self.variety_encoder = LabelEncoder()\n",
    "                # Use example variety classes\n",
    "                self.variety_encoder.classes_ = np.array(['ADT45', 'Ariete', 'B40', 'BRS10', 'BRS30', 'BRS43', \n",
    "                                                 'Cirad141', 'Csl3', 'IET1444', 'Khazar', 'MTL119', \n",
    "                                                 'MTU1010', 'Pusa44', 'Spandana', 'TeqingMarshal', 'Varalu'])\n",
    "                self.num_varieties = len(self.variety_encoder.classes_)\n",
    "                print(f\"Created fallback variety encoder with {self.num_varieties} classes\")\n",
    "            \n",
    "            # Load or create disease encoder\n",
    "            disease_encoder_path = 'disease_label_encoder.joblib'\n",
    "            if os.path.exists(disease_encoder_path):\n",
    "                self.disease_encoder = joblib.load(disease_encoder_path)\n",
    "                self.disease_classes = self.disease_encoder.classes_\n",
    "                self.num_diseases = len(self.disease_classes)\n",
    "                print(f\"Loaded disease encoder with {self.num_diseases} classes\")\n",
    "            else:\n",
    "                # Try to infer from folder structure\n",
    "                if os.path.exists('train_images'):\n",
    "                    disease_folders = [d for d in os.listdir('train_images') \n",
    "                                    if os.path.isdir(os.path.join('train_images', d))]\n",
    "                    if disease_folders:\n",
    "                        self.disease_classes = sorted(disease_folders)\n",
    "                        self.num_diseases = len(self.disease_classes)\n",
    "                        print(f\"Found {self.num_diseases} disease classes from folders\")\n",
    "                    else:\n",
    "                        # Default disease classes from assignment\n",
    "                        self.disease_classes = ['tungro', 'bacterial_leaf_blight', 'bacterial_leaf_streak', \n",
    "                                            'bacterial_panicle_blight', 'blast', 'brown_spot', \n",
    "                                            'dead_heart', 'downy_mildew', 'hispa', 'normal']\n",
    "                        self.num_diseases = len(self.disease_classes)\n",
    "                        print(f\"Using default {self.num_diseases} disease classes\")\n",
    "                else:\n",
    "                    # Default disease classes\n",
    "                    self.disease_classes = ['tungro', 'bacterial_leaf_blight', 'bacterial_leaf_streak', \n",
    "                                        'bacterial_panicle_blight', 'blast', 'brown_spot', \n",
    "                                        'dead_heart', 'downy_mildew', 'hispa', 'normal']\n",
    "                    self.num_diseases = len(self.disease_classes)\n",
    "                    print(f\"Using default {self.num_diseases} disease classes\")\n",
    "                \n",
    "                # Create a LabelEncoder for diseases\n",
    "                from sklearn.preprocessing import LabelEncoder\n",
    "                self.disease_encoder = LabelEncoder()\n",
    "                self.disease_encoder.fit(self.disease_classes)\n",
    "            \n",
    "            # Load or create age statistics for normalization\n",
    "            age_stats_path = os.path.join(self.models_path, 'age_stats_kfold.json')\n",
    "            if os.path.exists(age_stats_path):\n",
    "                with open(age_stats_path, 'r') as f:\n",
    "                    self.age_stats = json.load(f)\n",
    "                print(f\"Loaded age statistics: mean={self.age_stats['mean']}, std={self.age_stats['std']}\")\n",
    "            else:\n",
    "                # Create fallback stats\n",
    "                self.age_stats = {\n",
    "                    'mean': 64.0436244835207,  # Example value\n",
    "                    'std': 8.9582253420494     # Example value\n",
    "                }\n",
    "                # Save the fallback stats\n",
    "                with open(age_stats_path, 'w') as f:\n",
    "                    json.dump(self.age_stats, f)\n",
    "                print(f\"Created fallback age statistics: mean={self.age_stats['mean']}, std={self.age_stats['std']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading encoders: {e}\")\n",
    "            # Set fallback values\n",
    "            self.num_varieties = 16\n",
    "            self.num_diseases = 10\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            self.variety_encoder = LabelEncoder()\n",
    "            self.variety_encoder.classes_ = np.array(['ADT45', 'Ariete', 'B40', 'BRS10', 'BRS30', 'BRS43', \n",
    "                                             'Cirad141', 'Csl3', 'IET1444', 'Khazar', 'MTL119', \n",
    "                                             'MTU1010', 'Pusa44', 'Spandana', 'TeqingMarshal', 'Varalu'])\n",
    "            \n",
    "            self.disease_encoder = LabelEncoder()\n",
    "            self.disease_classes = ['tungro', 'bacterial_leaf_blight', 'bacterial_leaf_streak', \n",
    "                                  'bacterial_panicle_blight', 'blast', 'brown_spot', \n",
    "                                  'dead_heart', 'downy_mildew', 'hispa', 'normal']\n",
    "            self.disease_encoder.fit(self.disease_classes)\n",
    "            \n",
    "            self.age_stats = {\n",
    "                'mean': 64.0436244835207,\n",
    "                'std': 8.9582253420494\n",
    "            }\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"Load trained models or create fallbacks\"\"\"\n",
    "        try:\n",
    "            # -------- DISEASE MODEL (Task 1) --------\n",
    "            print(\"Creating disease classification model...\")\n",
    "            self.disease_model = create_vit_disease_classifier()\n",
    "            self.disease_model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            # Check if weights are available\n",
    "            disease_weights_path = os.path.join(self.models_path, 'vit_label_weights.weights.h5')\n",
    "            if os.path.exists(disease_weights_path):\n",
    "                print(f\"Loading disease model weights from {disease_weights_path}\")\n",
    "                try:\n",
    "                    self.disease_model.load_weights(disease_weights_path)\n",
    "                    self.disease_model_loaded = True\n",
    "                    print(\"Successfully loaded disease model weights\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading disease model weights: {e}\")\n",
    "                    self.disease_model_loaded = False\n",
    "            else:\n",
    "                print(\"Disease model weights not found. Using uninitialized model.\")\n",
    "                self.disease_model_loaded = False\n",
    "            \n",
    "            # -------- VARIETY MODEL (Task 2) --------\n",
    "            print(\"Creating variety classification model...\")\n",
    "            self.variety_model = create_vit_variety_classifier()\n",
    "            self.variety_model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            # Check if weights are available\n",
    "            variety_weights_path = os.path.join(self.models_path, 'vit_variety_weights.weights.h5')\n",
    "            if os.path.exists(variety_weights_path):\n",
    "                print(f\"Loading variety model weights from {variety_weights_path}\")\n",
    "                try:\n",
    "                    self.variety_model.load_weights(variety_weights_path)\n",
    "                    self.variety_model_loaded = True\n",
    "                    print(\"Successfully loaded variety model weights\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading variety model weights: {e}\")\n",
    "                    self.variety_model_loaded = False\n",
    "            else:\n",
    "                print(\"Variety model weights not found. Using uninitialized model.\")\n",
    "                self.variety_model_loaded = False\n",
    "            \n",
    "            # -------- AGE MODELS (ENSEMBLE) (Task 3) --------\n",
    "            print(\"Loading age regression ensemble models...\")\n",
    "            self.age_ensemble_models = []\n",
    "            k_folds = 3  # Number of models in the ensemble\n",
    "            \n",
    "            for fold in range(1, k_folds + 1):\n",
    "                # Create a fresh model\n",
    "                age_model = create_vit_regressor()\n",
    "                \n",
    "                # Compile model\n",
    "                optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "                age_model.compile(\n",
    "                    optimizer=optimizer,\n",
    "                    loss='mean_absolute_error',\n",
    "                    metrics=['mae', 'mse']\n",
    "                )\n",
    "                \n",
    "                # Load weights\n",
    "                age_weights_path = os.path.join(self.kfold_models_path, f'best_vit_age_model_fold_{fold}.weights.h5')\n",
    "                \n",
    "                if os.path.exists(age_weights_path):\n",
    "                    age_model.load_weights(age_weights_path)\n",
    "                    print(f\"Loaded weights for age model fold {fold}\")\n",
    "                    \n",
    "                    # Add to ensemble with normalization stats\n",
    "                    self.age_ensemble_models.append((age_model, self.age_stats['mean'], self.age_stats['std']))\n",
    "                else:\n",
    "                    print(f\"Warning: Could not find weights for age model fold {fold}\")\n",
    "            \n",
    "            # Check if at least one age model was loaded\n",
    "            if self.age_ensemble_models:\n",
    "                self.age_model_loaded = True\n",
    "                print(f\"Successfully loaded {len(self.age_ensemble_models)} age models for ensemble\")\n",
    "            else:\n",
    "                # Create a single fallback model\n",
    "                fallback_age_model = create_vit_regressor()\n",
    "                fallback_age_model.compile(\n",
    "                    optimizer='adam',\n",
    "                    loss='mean_absolute_error',\n",
    "                    metrics=['mae']\n",
    "                )\n",
    "                self.age_ensemble_models = [(fallback_age_model, self.age_stats['mean'], self.age_stats['std'])]\n",
    "                self.age_model_loaded = False\n",
    "                print(\"No age model weights found. Using uninitialized fallback model.\")\n",
    "            \n",
    "            print(\"Models initialized successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading models: {e}\")\n",
    "            # Set flags to indicate models couldn't be loaded\n",
    "            self.variety_model_loaded = False\n",
    "            self.disease_model_loaded = False\n",
    "            self.age_model_loaded = False\n",
    "            \n",
    "    def predict_diseases(self, image_path):\n",
    "        \"\"\"Predict disease for an image\"\"\"\n",
    "        img_array = preprocess_image(image_path)\n",
    "        \n",
    "        if self.disease_model_loaded and img_array is not None:\n",
    "            disease_pred = self.disease_model.predict(img_array, verbose=0)\n",
    "            top_disease_index = np.argmax(disease_pred[0])\n",
    "            return self.disease_classes[top_disease_index]\n",
    "        else:\n",
    "            # Return a default prediction if the model isn't loaded\n",
    "            return \"normal\"\n",
    "    \n",
    "    def predict_variety(self, image_path):\n",
    "        \"\"\"Predict variety for an image\"\"\"\n",
    "        img_array = preprocess_image(image_path)\n",
    "        \n",
    "        if self.variety_model_loaded and img_array is not None:\n",
    "            variety_pred = self.variety_model.predict(img_array, verbose=0)\n",
    "            top_variety_index = np.argmax(variety_pred[0])\n",
    "            return self.variety_encoder.classes_[top_variety_index]\n",
    "        else:\n",
    "            # Return a default prediction if the model isn't loaded\n",
    "            return \"Ariete\"\n",
    "    \n",
    "    def predict_age(self, image_path):\n",
    "        \"\"\"Predict age for an image\"\"\"\n",
    "        if self.age_model_loaded and self.age_ensemble_models:\n",
    "            age_img_array = preprocess_age_image(image_path)\n",
    "            \n",
    "            # Make predictions with each model in the ensemble\n",
    "            all_age_predictions = []\n",
    "            \n",
    "            for model, age_mean, age_std in self.age_ensemble_models:\n",
    "                predictions_norm = model.predict(age_img_array, verbose=0)\n",
    "                predictions_original = predictions_norm.flatten() * age_std + age_mean\n",
    "                all_age_predictions.append(predictions_original)\n",
    "            \n",
    "            # Average predictions across all models in the ensemble\n",
    "            ensemble_age_prediction = np.mean(all_age_predictions, axis=0)[0]\n",
    "            age_pred = int(round(ensemble_age_prediction))  # Round to nearest integer\n",
    "            return str(age_pred)\n",
    "        else:\n",
    "            # Return a default prediction if the model isn't loaded\n",
    "            return \"65\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a26d9",
   "metadata": {},
   "source": [
    "# Main function to run predictions and create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4848bb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoders and models...\n",
      "Loaded variety encoder with 10 classes\n",
      "Loaded disease encoder with 10 classes\n",
      "Loaded age statistics: mean=64.0436244835207, std=8.9582253420494\n",
      "Creating disease classification model...\n",
      "Loading disease model weights from c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning\\paddy_models\\vit_label_weights.weights.h5\n",
      "Successfully loaded disease model weights\n",
      "Creating variety classification model...\n",
      "Loading variety model weights from c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning\\paddy_models\\vit_variety_weights.weights.h5\n",
      "Successfully loaded variety model weights\n",
      "Loading age regression ensemble models...\n",
      "Loaded weights for age model fold 1\n",
      "Loaded weights for age model fold 2\n",
      "Loaded weights for age model fold 3\n",
      "Successfully loaded 3 age models for ensemble\n",
      "Models initialized successfully\n",
      "Processing 3469 test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3469/3469 [26:01<00:00,  2.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions completed and saved to prediction_submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_predictions():\n",
    "    # Initialize the model handler\n",
    "    model_handler = PaddyModelHandler()\n",
    "    \n",
    "    # Define paths\n",
    "    home_path = os.getcwd()\n",
    "    test_images_path = os.path.join(home_path, 'test_images')\n",
    "    \n",
    "    # Load the template submission CSV\n",
    "    submission_template = pd.read_csv('prediction_submission.csv')\n",
    "    \n",
    "    # Check if test images directory exists\n",
    "    if not os.path.exists(test_images_path):\n",
    "        print(f\"Error: Test images directory not found at {test_images_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing {len(submission_template)} test images...\")\n",
    "    \n",
    "    # Process each image and make predictions\n",
    "    for i, row in tqdm(submission_template.iterrows(), total=len(submission_template)):\n",
    "        image_id = row['image_id']\n",
    "        image_path = os.path.join(test_images_path, image_id)\n",
    "        \n",
    "        # Skip if image doesn't exist\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Warning: Image {image_id} not found in test_images directory\")\n",
    "            continue\n",
    "        \n",
    "        # Make predictions for each task\n",
    "        disease_pred = model_handler.predict_diseases(image_path)\n",
    "        variety_pred = model_handler.predict_variety(image_path)\n",
    "        age_pred = model_handler.predict_age(image_path)\n",
    "        \n",
    "        # Update the submission template\n",
    "        submission_template.at[i, 'label'] = disease_pred\n",
    "        submission_template.at[i, 'variety'] = variety_pred\n",
    "        submission_template.at[i, 'age'] = age_pred\n",
    "    \n",
    "    # Save the submission file\n",
    "    submission_template.to_csv('prediction_submission.csv', index=False)\n",
    "    print(f\"Predictions completed and saved to prediction_submission.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
