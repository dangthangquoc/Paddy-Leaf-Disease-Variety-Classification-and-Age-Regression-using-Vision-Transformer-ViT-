{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-Efficient Version for Task 2: Variety Classification\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, callbacks, Sequential, Model, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(45)\n",
    "\n",
    "# Set Load Truncated Images to True\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable memory growth for GPU if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Configuration and Constants\n",
    "batch_size = 32  # Reduced batch size\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "# Define paths\n",
    "HOME_PATH = os.getcwd() + \"/\"\n",
    "TRAIN_IMG_PATH = HOME_PATH + 'train_images'\n",
    "TEST_IMG_PATH = HOME_PATH + 'test_images'\n",
    "META_TRAIN_PATH = HOME_PATH + 'meta_train.csv'\n",
    "CHECKPOINT_MODEL_PATH = HOME_PATH + 'paddy_models/best_vit_variety_model.keras'\n",
    "FINAL_MODEL_PATH = HOME_PATH + 'paddy_models/vit_variety_model.keras'\n",
    "FINAL_WEIGHTS_PATH = HOME_PATH + 'paddy_models/vit_variety_weights.weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f753c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('paddy_models', exist_ok=True)\n",
    "\n",
    "# Load metadata\n",
    "print(\"Loading metadata...\")\n",
    "meta_train = pd.read_csv(META_TRAIN_PATH)\n",
    "\n",
    "# Check unique varieties\n",
    "unique_varieties = meta_train['variety'].unique()\n",
    "num_varieties = len(unique_varieties)\n",
    "print(f\"Number of unique varieties: {num_varieties}\")\n",
    "print(f\"Varieties: {unique_varieties}\")\n",
    "\n",
    "# Create variety label encoder\n",
    "variety_encoder = LabelEncoder()\n",
    "variety_labels = variety_encoder.fit_transform(meta_train['variety'])\n",
    "variety_to_idx = {variety: idx for idx, variety in enumerate(variety_encoder.classes_)}\n",
    "\n",
    "# Save label encoder for later use\n",
    "import joblib\n",
    "joblib.dump(variety_encoder, 'variety_label_encoder.joblib')\n",
    "\n",
    "# Create a DataFrame with file paths and variety labels\n",
    "def create_file_df(meta_df):\n",
    "    \"\"\"Create a DataFrame with file paths and variety indices\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for idx, row in tqdm(meta_df.iterrows(), total=len(meta_df)):\n",
    "        image_id = row['image_id']\n",
    "        variety = row['variety']\n",
    "        label = row['label']  # Disease label to find the folder\n",
    "        \n",
    "        # Construct image path\n",
    "        img_path = os.path.join(TRAIN_IMG_PATH, label, image_id)\n",
    "        \n",
    "        if os.path.exists(img_path):\n",
    "            data.append({\n",
    "                'file_path': img_path,\n",
    "                'variety_label': variety_to_idx[variety],\n",
    "                'variety_name': variety,\n",
    "                'image_id': image_id\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create file DataFrame\n",
    "print(\"Creating file DataFrame...\")\n",
    "file_df = create_file_df(meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, test_df = train_test_split(\n",
    "    file_df, test_size=0.3, random_state=42, stratify=file_df['variety_label']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters\n",
    "num_classes = num_varieties\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# Configure the hyperparameters\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "image_size = 72 \n",
    "patch_size = 6 \n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83bcd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow Dataset\n",
    "def parse_image(file_path, label):\n",
    "    \"\"\"Parse image from file path\"\"\"\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(df, batch_size=32, is_training=True):\n",
    "    \"\"\"Create TensorFlow dataset from DataFrame\"\"\"\n",
    "    file_paths = df['file_path'].values\n",
    "    labels = df['variety_label'].values\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "        dataset = dataset.repeat()  # Repeat dataset for multiple epochs\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = create_dataset(train_df, batch_size=batch_size, is_training=True)\n",
    "test_dataset = create_dataset(test_df, batch_size=batch_size, is_training=False)\n",
    "\n",
    "# Create validation split\n",
    "val_split = 0.3\n",
    "val_size = int(len(train_df) * val_split)\n",
    "val_dataset = train_dataset.take(val_size)\n",
    "train_dataset = train_dataset.skip(val_size)\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = len(train_df) // batch_size\n",
    "validation_steps = len(test_df) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ec52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "# Normalization layer (will be adapted during training)\n",
    "normalization = layers.Normalization()\n",
    "\n",
    "# Adapt normalization on a sample of data\n",
    "sample_dataset = train_dataset.take(5)\n",
    "normalization.adapt(sample_dataset.map(lambda x, y: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc091bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer perceptron (MLP)\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "# Implementing patch creation as a layer\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "# Implementing the patch encoding layer\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "# ViT Model for Variety Classification\n",
    "def create_vit_variety_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Normalize data\n",
    "    normalized = normalization(inputs)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(normalized)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs\n",
    "    logits = layers.Dense(num_classes, activation='softmax', name='variety_output')(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364de261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=CHECKPOINT_MODEL_PATH,\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    cooldown=3,\n",
    "    min_lr=0\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup and Training\n",
    "def train_variety_model(model):\n",
    "    optimizer = keras.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=[checkpoint, reduce_lr, early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "    print(f\"Test accuracy: {round(test_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# Create and train model\n",
    "vit_variety_classifier = create_vit_variety_classifier()\n",
    "vit_variety_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = train_variety_model(vit_variety_classifier)\n",
    "\n",
    "# Save model\n",
    "vit_variety_classifier.save(FINAL_MODEL_PATH)\n",
    "vit_variety_classifier.save_weights(FINAL_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3593cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Learning Curves\n",
    "def plot_training_curves(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_curves(history)\n",
    "\n",
    "# Generate Predictions for Test Set\n",
    "def create_test_dataset(test_path):\n",
    "    \"\"\"Create dataset for test images\"\"\"\n",
    "    test_files = []\n",
    "    test_ids = []\n",
    "    \n",
    "    for img_name in os.listdir(test_path):\n",
    "        if img_name.endswith('.jpg'):\n",
    "            img_path = os.path.join(test_path, img_name)\n",
    "            test_files.append(img_path)\n",
    "            test_ids.append(img_name)\n",
    "    \n",
    "    # Create dataset with dummy labels (not used)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((test_files, [0] * len(test_files)))\n",
    "    dataset = dataset.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset, test_ids\n",
    "\n",
    "# Create test dataset\n",
    "print(\"Creating test dataset...\")\n",
    "test_pred_dataset, test_image_ids = create_test_dataset(TEST_IMG_PATH)\n",
    "\n",
    "# Generate predictions\n",
    "print(\"Generating predictions...\")\n",
    "predictions = vit_variety_classifier.predict(test_pred_dataset)\n",
    "predicted_variety_indices = np.argmax(predictions, axis=1)\n",
    "predicted_varieties = variety_encoder.inverse_transform(predicted_variety_indices)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_id': test_image_ids,\n",
    "    'variety': predicted_varieties\n",
    "})\n",
    "\n",
    "# Save predictions\n",
    "submission_df.to_csv('variety_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'variety_predictions.csv'\")\n",
    "\n",
    "# Create a more detailed submission file\n",
    "confidence_df = pd.DataFrame({\n",
    "    'image_id': test_image_ids,\n",
    "    'variety': predicted_varieties,\n",
    "    'confidence': np.max(predictions, axis=1)\n",
    "})\n",
    "\n",
    "# Add top 3 predictions for each image\n",
    "for i in range(3):\n",
    "    top_n_indices = np.argsort(predictions, axis=1)[:, -(i+1)]\n",
    "    confidence_df[f'variety_top_{i+1}'] = variety_encoder.inverse_transform(top_n_indices)\n",
    "    confidence_df[f'confidence_top_{i+1}'] = np.sort(predictions, axis=1)[:, -(i+1)]\n",
    "\n",
    "confidence_df.to_csv('variety_predictions_detailed.csv', index=False)\n",
    "print(\"Detailed predictions saved to 'variety_predictions_detailed.csv'\")\n",
    "\n",
    "# Model evaluation and analysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions for validation set\n",
    "print(\"Generating validation predictions...\")\n",
    "val_predictions = []\n",
    "val_true_labels = []\n",
    "\n",
    "for batch in test_dataset:\n",
    "    images, labels = batch\n",
    "    preds = vit_variety_classifier.predict(images, verbose=0)\n",
    "    val_predictions.extend(np.argmax(preds, axis=1))\n",
    "    val_true_labels.extend(labels.numpy())\n",
    "\n",
    "# Create classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_true_labels, val_predictions, \n",
    "                          target_names=variety_encoder.classes_))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(val_true_labels, val_predictions)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=variety_encoder.classes_,\n",
    "            yticklabels=variety_encoder.classes_)\n",
    "plt.title('Confusion Matrix for Variety Classification')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTraining completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
