{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1f4afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, callbacks, saving\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "np.random.seed(45)\n",
    "\n",
    "print(tf.__version__)\n",
    "import glob\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc52ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:50,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10407 images\n",
      "Age range: 0 to 9 days\n",
      "Average age: 5.39 days\n"
     ]
    }
   ],
   "source": [
    "# Load metadata to get age information\n",
    "HOME_PATH = os.getcwd() + \"/\"\n",
    "meta_train = pd.read_csv(HOME_PATH + 'meta_train.csv')\n",
    "\n",
    "# Create mapping from image_id to age\n",
    "image_to_age = dict(zip(meta_train['image_id'], meta_train['age']))\n",
    "\n",
    "# Load images with age labels\n",
    "def load_images_with_age(paths):\n",
    "    data = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    for label, path in tqdm(enumerate(paths)):\n",
    "        for img_path in os.listdir(path):\n",
    "            image = np.array(Image.open(os.path.join(path,img_path)).convert('RGB').resize((256,256)))\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "    return np.array(data), np.asarray(labels)\n",
    "\n",
    "# Load all training images\n",
    "print(\"Loading training images...\")\n",
    "images, ages = load_images_with_age(glob.glob(HOME_PATH + 'train_images/*'))\n",
    "\n",
    "print(f\"Loaded {len(images)} images\")\n",
    "print(f\"Age range: {ages.min()} to {ages.max()} days\")\n",
    "print(f\"Average age: {ages.mean():.2f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee72539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "image_size = 72\n",
    "patch_size = 6\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]\n",
    "k_folds = 5  # Number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b898158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP helper function\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):  # Add **kwargs to handle extra arguments\n",
    "        super(Patches, self).__init__(**kwargs)  # Pass kwargs to parent constructor\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Patches, self).get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        patch_size = config.pop(\"patch_size\")  # Extract your custom parameter\n",
    "        # Create instance with your param and pass remaining config as kwargs\n",
    "        return cls(patch_size=patch_size, **config)\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):  # Add **kwargs\n",
    "        super(PatchEncoder, self).__init__(**kwargs)  # Pass kwargs to parent\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(PatchEncoder, self).get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\": self.projection_dim\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        num_patches = config.pop(\"num_patches\")  # Extract your custom parameters\n",
    "        projection_dim = config.pop(\"projection_dim\")\n",
    "        # Create instance with your params and pass remaining config as kwargs\n",
    "        return cls(num_patches=num_patches, projection_dim=projection_dim, **config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a3cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT Model for Age Regression with adjustable input shape for preprocessing\n",
    "def create_vit_regressor(input_images):\n",
    "    # Create data augmentation inside model\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.Normalization(),\n",
    "            layers.Resizing(image_size, image_size),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(factor=0.02),\n",
    "            layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "    \n",
    "    # Adapt normalization layer to current fold's data\n",
    "    data_augmentation.layers[0].adapt(input_images)\n",
    "    \n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    # Augment data\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    \n",
    "    # Encode patches\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        \n",
    "        # Create a multi-head attention layer\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        \n",
    "        # Skip connection 1\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        \n",
    "        # Layer normalization 2\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        \n",
    "        # MLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        \n",
    "        # Skip connection 2\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    \n",
    "    # Add MLP\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    \n",
    "    # Output layer for regression (single neuron for age)\n",
    "    output = layers.Dense(1, activation='linear')(features)\n",
    "    \n",
    "    # Create the Keras model\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "def perform_kfold_training():\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    fold_histories = []\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    # Create directory for k-fold models\n",
    "    kfold_model_dir = HOME_PATH + 'paddy_models/kfold_models/'\n",
    "    os.makedirs(kfold_model_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nStarting {k_folds}-Fold Cross Validation...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(images), 1):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training Fold {fold}/{k_folds}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Split data for current fold\n",
    "        X_train_fold, X_val_fold = images[train_idx], images[val_idx]\n",
    "        y_train_fold, y_val_fold = ages[train_idx], ages[val_idx]\n",
    "        \n",
    "        # Calculate age statistics for current fold\n",
    "        age_mean_fold = y_train_fold.mean()\n",
    "        age_std_fold = y_train_fold.std()\n",
    "        \n",
    "        # Normalize ages for current fold\n",
    "        y_train_norm_fold = (y_train_fold - age_mean_fold) / age_std_fold\n",
    "        y_val_norm_fold = (y_val_fold - age_mean_fold) / age_std_fold\n",
    "        \n",
    "        print(f\"Training samples: {len(X_train_fold)}\")\n",
    "        print(f\"Validation samples: {len(X_val_fold)}\")\n",
    "        print(f\"Age mean: {age_mean_fold:.2f}, std: {age_std_fold:.2f}\")\n",
    "        \n",
    "        # Create model for current fold\n",
    "        model = create_vit_regressor(X_train_fold)\n",
    "        \n",
    "        # Compile model\n",
    "        optimizer = keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mean_absolute_error',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        filepath = f\"{kfold_model_dir}best_vit_age_model_fold_{fold}.weights.h5\"\n",
    "        \n",
    "        # Modify the checkpoint callback\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=filepath,\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,  # Only save weights, not the whole model\n",
    "            mode='min'\n",
    "        )\n",
    "        \n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.2,\n",
    "            patience=8,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "            min_delta=0.001,\n",
    "            cooldown=2,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "        \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train model for current fold\n",
    "        history = model.fit(\n",
    "            x=X_train_fold,\n",
    "            y=y_train_norm_fold,\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            validation_data=(X_val_fold, y_val_norm_fold),\n",
    "            callbacks=[checkpoint, reduce_lr, early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_predictions = model.predict(X_val_fold)\n",
    "        val_predictions_original = val_predictions.flatten() * age_std_fold + age_mean_fold\n",
    "        y_val_original = y_val_fold\n",
    "        \n",
    "        mae = mean_absolute_error(y_val_original, val_predictions_original)\n",
    "        mse = mean_squared_error(y_val_original, val_predictions_original)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Store results\n",
    "        fold_result = {\n",
    "            'fold': fold,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'mse': mse,\n",
    "            'age_mean': age_mean_fold,\n",
    "            'age_std': age_std_fold,\n",
    "            'best_val_loss': min(history.history['val_loss']),\n",
    "            'final_val_loss': history.history['val_loss'][-1]\n",
    "        }\n",
    "        fold_results.append(fold_result)\n",
    "        fold_histories.append(history)\n",
    "        \n",
    "        # Then later instead of loading the model, use:\n",
    "        # Create a fresh model\n",
    "        best_model = create_vit_regressor(X_train_fold)\n",
    "        best_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mean_absolute_error',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        # Load just the weights\n",
    "        best_model.load_weights(filepath)\n",
    "        \n",
    "        ensemble_predictions.append((best_model, age_mean_fold, age_std_fold))\n",
    "        \n",
    "        print(f\"\\nFold {fold} Results:\")\n",
    "        print(f\"Validation MAE: {mae:.2f} days\")\n",
    "        print(f\"Validation RMSE: {rmse:.2f} days\")\n",
    "        print(f\"Best validation loss: {fold_result['best_val_loss']:.4f}\")\n",
    "        \n",
    "        # Clean up model from memory\n",
    "        del model\n",
    "        del best_model\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    return fold_results, fold_histories, ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2668fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/5\n",
      "==================================================\n",
      "Training samples: 8325\n",
      "Validation samples: 2082\n",
      "Age mean: 5.40, std: 2.55\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step - loss: 2.0755 - mae: 2.0755 - mse: 16.7925\n",
      "Epoch 1: val_loss improved from inf to 0.76822, saving model to c:\\Users\\Admin\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.weights.h5\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 602ms/step - loss: 2.0723 - mae: 2.0723 - mse: 16.7466 - val_loss: 0.7682 - val_mae: 0.7682 - val_mse: 0.9142 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 148ms/step\n",
      "\n",
      "Fold 1 Results:\n",
      "Validation MAE: 1.96 days\n",
      "Validation RMSE: 2.44 days\n",
      "Best validation loss: 0.7682\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/5\n",
      "==================================================\n",
      "Training samples: 8325\n",
      "Validation samples: 2082\n",
      "Age mean: 5.42, std: 2.54\n",
      "\u001b[1m 15/261\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 559ms/step - loss: 7.5598 - mae: 7.5598 - mse: 113.7386"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Perform k-fold training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fold_results, fold_histories, ensemble_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mperform_kfold_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Analyze k-fold results\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 83\u001b[0m, in \u001b[0;36mperform_kfold_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[0;32m     75\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     76\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     80\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Train model for current fold\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_norm_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_norm_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[0;32m     94\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_fold)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perform k-fold training\n",
    "fold_results, fold_histories, ensemble_predictions = perform_kfold_training()\n",
    "\n",
    "# Analyze k-fold results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"K-Fold Cross Validation Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "mae_scores = [result['mae'] for result in fold_results]\n",
    "rmse_scores = [result['rmse'] for result in fold_results]\n",
    "\n",
    "print(f\"\\nMAE per fold: {mae_scores}\")\n",
    "print(f\"RMSE per fold: {rmse_scores}\")\n",
    "print(f\"\\nAverage MAE: {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "print(f\"Average RMSE: {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8415bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k-fold results\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "results_df.to_csv(HOME_PATH + 'kfold_results.csv', index=False)\n",
    "\n",
    "# Plot k-fold training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('K-Fold Training History', fontsize=16)\n",
    "\n",
    "# Plot loss\n",
    "axes[0, 0].set_title('Training Loss by Fold')\n",
    "for i, history in enumerate(fold_histories):\n",
    "    axes[0, 0].plot(history.history['loss'], label=f'Fold {i+1}', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss (MAE)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot validation loss\n",
    "axes[0, 1].set_title('Validation Loss by Fold')\n",
    "for i, history in enumerate(fold_histories):\n",
    "    axes[0, 1].plot(history.history['val_loss'], label=f'Fold {i+1}', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Validation Loss (MAE)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot MAE\n",
    "axes[1, 0].set_title('Training MAE by Fold')\n",
    "for i, history in enumerate(fold_histories):\n",
    "    axes[1, 0].plot(history.history['mae'], label=f'Fold {i+1}', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('MAE')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot validation MAE\n",
    "axes[1, 1].set_title('Validation MAE by Fold')\n",
    "for i, history in enumerate(fold_histories):\n",
    "    axes[1, 1].plot(history.history['val_mae'], label=f'Fold {i+1}', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Validation MAE')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(HOME_PATH + 'kfold_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot fold comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "folds = [f'Fold {i+1}' for i in range(k_folds)]\n",
    "x = np.arange(len(folds))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, mae_scores, width, label='MAE', alpha=0.8)\n",
    "plt.bar(x + width/2, rmse_scores, width, label='RMSE', alpha=0.8)\n",
    "\n",
    "plt.ylabel('Error (days)')\n",
    "plt.title('Performance Comparison Across Folds')\n",
    "plt.xticks(x, folds)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(HOME_PATH + 'kfold_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Generate ensemble predictions for test set\n",
    "def load_test_images():\n",
    "    test_data = []\n",
    "    test_ids = []\n",
    "    \n",
    "    test_path = HOME_PATH + 'test_images/'\n",
    "    for img_file in tqdm(os.listdir(test_path)):\n",
    "        if img_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(test_path, img_file)\n",
    "            image = np.array(Image.open(img_path).convert('RGB').resize((256, 256)))\n",
    "            test_data.append(image)\n",
    "            test_ids.append(img_file.split('.')[0])\n",
    "    \n",
    "    return np.array(test_data), test_ids\n",
    "\n",
    "# Load test images\n",
    "print(\"\\nLoading test images...\")\n",
    "test_images, test_ids = load_test_images()\n",
    "\n",
    "# Ensemble prediction\n",
    "print(\"\\nMaking ensemble predictions...\")\n",
    "all_predictions = []\n",
    "\n",
    "for model, age_mean, age_std in ensemble_predictions:\n",
    "    predictions_norm = model.predict(test_images, verbose=0)\n",
    "    predictions_original = predictions_norm.flatten() * age_std + age_mean\n",
    "    all_predictions.append(predictions_original)\n",
    "\n",
    "# Average predictions across folds\n",
    "ensemble_predictions_avg = np.mean(all_predictions, axis=0)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_id': test_ids,\n",
    "    'age': ensemble_predictions_avg.astype(int).astype(str)\n",
    "})\n",
    "\n",
    "# Save ensemble predictions\n",
    "submission_df.to_csv(HOME_PATH + 'age_predictions_kfold_ensemble.csv', index=False)\n",
    "\n",
    "print(f\"\\nEnsemble prediction statistics:\")\n",
    "print(f\"Min predicted age: {ensemble_predictions_avg.min():.2f} days\")\n",
    "print(f\"Max predicted age: {ensemble_predictions_avg.max():.2f} days\")\n",
    "print(f\"Mean predicted age: {ensemble_predictions_avg.mean():.2f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save individual fold predictions for analysis\n",
    "individual_predictions_df = pd.DataFrame({\n",
    "    'image_id': test_ids,\n",
    "    **{f'fold_{i+1}_prediction': pred for i, pred in enumerate(all_predictions)}\n",
    "})\n",
    "individual_predictions_df.to_csv(HOME_PATH + 'age_predictions_individual_folds.csv', index=False)\n",
    "\n",
    "# Analyze prediction variance across folds\n",
    "prediction_std = np.std(all_predictions, axis=0)\n",
    "prediction_variance_df = pd.DataFrame({\n",
    "    'image_id': test_ids,\n",
    "    'ensemble_prediction': ensemble_predictions_avg,\n",
    "    'prediction_std': prediction_std,\n",
    "    'coefficient_of_variation': prediction_std / ensemble_predictions_avg\n",
    "})\n",
    "prediction_variance_df.to_csv(HOME_PATH + 'prediction_variance_analysis.csv', index=False)\n",
    "\n",
    "print(f\"\\nPrediction variance statistics:\")\n",
    "print(f\"Average standard deviation across predictions: {prediction_std.mean():.2f}\")\n",
    "print(f\"Maximum standard deviation: {prediction_std.max():.2f}\")\n",
    "print(f\"Images with high prediction variance (std > 10): {sum(prediction_std > 10)}\")\n",
    "\n",
    "# Save age statistics (using average from all folds)\n",
    "age_stats = {\n",
    "    'mean': np.mean([result['age_mean'] for result in fold_results]),\n",
    "    'std': np.mean([result['age_std'] for result in fold_results])\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(HOME_PATH + 'age_stats_kfold.json', 'w') as f:\n",
    "    json.dump(age_stats, f)\n",
    "\n",
    "print(\"\\nK-fold cross-validation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
