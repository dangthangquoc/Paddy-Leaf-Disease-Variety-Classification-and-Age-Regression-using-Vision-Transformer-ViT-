{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, callbacks\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "np.random.seed(45)\n",
    "\n",
    "print(tf.__version__)\n",
    "import glob\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc52ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata to get age information\n",
    "HOME_PATH = os.getcwd() + \"/\"\n",
    "meta_train = pd.read_csv(HOME_PATH + 'meta_train.csv')\n",
    "\n",
    "# Create mapping from image_id to age\n",
    "image_to_age = dict(zip(meta_train['image_id'], meta_train['age']))\n",
    "\n",
    "# Load images with age labels\n",
    "def load_images_with_age(paths):\n",
    "    data = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    for label, path in tqdm(enumerate(paths)):\n",
    "        for img_path in os.listdir(path):\n",
    "            image = np.array(Image.open(os.path.join(path,img_path)).convert('RGB').resize((256,256)))\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "    return np.array(data), np.asarray(labels)\n",
    "\n",
    "# Load all training images\n",
    "print(\"Loading training images...\")\n",
    "images, ages = load_images_with_age(glob.glob(HOME_PATH + 'train_images/*'))\n",
    "\n",
    "print(f\"Loaded {len(images)} images\")\n",
    "print(f\"Age range: {ages.min()} to {ages.max()} days\")\n",
    "print(f\"Average age: {ages.mean():.2f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee72539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "image_size = 72\n",
    "patch_size = 6\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]\n",
    "k_folds = 5  # Number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b898158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "Loading training images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:05,  6.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10407 images\n",
      "Age range: 0 to 9 days\n",
      "Average age: 5.39 days\n"
     ]
    }
   ],
   "source": [
    "# MLP helper function\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "# Patches layer\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "# Patch encoder\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT Model for Age Regression with adjustable input shape for preprocessing\n",
    "def create_vit_regressor(input_images):\n",
    "    # Create data augmentation inside model\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.Normalization(),\n",
    "            layers.Resizing(image_size, image_size),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(factor=0.02),\n",
    "            layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "    \n",
    "    # Adapt normalization layer to current fold's data\n",
    "    data_augmentation.layers[0].adapt(input_images)\n",
    "    \n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    # Augment data\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    \n",
    "    # Encode patches\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        \n",
    "        # Create a multi-head attention layer\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        \n",
    "        # Skip connection 1\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        \n",
    "        # Layer normalization 2\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        \n",
    "        # MLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        \n",
    "        # Skip connection 2\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    \n",
    "    # Add MLP\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    \n",
    "    # Output layer for regression (single neuron for age)\n",
    "    output = layers.Dense(1, activation='linear')(features)\n",
    "    \n",
    "    # Create the Keras model\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "def perform_kfold_training():\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    fold_histories = []\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    # Create directory for k-fold models\n",
    "    kfold_model_dir = HOME_PATH + 'paddy_models/kfold_models/'\n",
    "    os.makedirs(kfold_model_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nStarting {k_folds}-Fold Cross Validation...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(images), 1):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training Fold {fold}/{k_folds}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Split data for current fold\n",
    "        X_train_fold, X_val_fold = images[train_idx], images[val_idx]\n",
    "        y_train_fold, y_val_fold = ages[train_idx], ages[val_idx]\n",
    "        \n",
    "        # Calculate age statistics for current fold\n",
    "        age_mean_fold = y_train_fold.mean()\n",
    "        age_std_fold = y_train_fold.std()\n",
    "        \n",
    "        # Normalize ages for current fold\n",
    "        y_train_norm_fold = (y_train_fold - age_mean_fold) / age_std_fold\n",
    "        y_val_norm_fold = (y_val_fold - age_mean_fold) / age_std_fold\n",
    "        \n",
    "        print(f\"Training samples: {len(X_train_fold)}\")\n",
    "        print(f\"Validation samples: {len(X_val_fold)}\")\n",
    "        print(f\"Age mean: {age_mean_fold:.2f}, std: {age_std_fold:.2f}\")\n",
    "        \n",
    "        # Create model for current fold\n",
    "        model = create_vit_regressor(X_train_fold)\n",
    "        \n",
    "        # Compile model\n",
    "        optimizer = keras.optimizers.AdamW(\n",
    "            learning_rate=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mean_absolute_error',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        filepath = f\"{kfold_model_dir}best_vit_age_model_fold_{fold}.keras\"\n",
    "        \n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=filepath,\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            mode='min'\n",
    "        )\n",
    "        \n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.2,\n",
    "            patience=8,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "            min_delta=0.001,\n",
    "            cooldown=2,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "        \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train model for current fold\n",
    "        history = model.fit(\n",
    "            x=X_train_fold,\n",
    "            y=y_train_norm_fold,\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            validation_data=(X_val_fold, y_val_norm_fold),\n",
    "            callbacks=[checkpoint, reduce_lr, early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_predictions = model.predict(X_val_fold)\n",
    "        val_predictions_original = val_predictions.flatten() * age_std_fold + age_mean_fold\n",
    "        y_val_original = y_val_fold\n",
    "        \n",
    "        mae = mean_absolute_error(y_val_original, val_predictions_original)\n",
    "        mse = mean_squared_error(y_val_original, val_predictions_original)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Store results\n",
    "        fold_result = {\n",
    "            'fold': fold,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'mse': mse,\n",
    "            'age_mean': age_mean_fold,\n",
    "            'age_std': age_std_fold,\n",
    "            'best_val_loss': min(history.history['val_loss']),\n",
    "            'final_val_loss': history.history['val_loss'][-1]\n",
    "        }\n",
    "        fold_results.append(fold_result)\n",
    "        fold_histories.append(history)\n",
    "        \n",
    "        # Load the best model for this fold and make predictions on all test data\n",
    "        best_model = keras.models.load_model(filepath)\n",
    "        ensemble_predictions.append((best_model, age_mean_fold, age_std_fold))\n",
    "        \n",
    "        print(f\"\\nFold {fold} Results:\")\n",
    "        print(f\"Validation MAE: {mae:.2f} days\")\n",
    "        print(f\"Validation RMSE: {rmse:.2f} days\")\n",
    "        print(f\"Best validation loss: {fold_result['best_val_loss']:.4f}\")\n",
    "        \n",
    "        # Clean up model from memory\n",
    "        del model\n",
    "        del best_model\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    return fold_results, fold_histories, ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/5\n",
      "==================================================\n",
      "Training samples: 8325\n",
      "Validation samples: 2082\n",
      "Age mean: 5.40, std: 2.55\n",
      "WARNING:tensorflow:From c:\\Users\\ThinkPad\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.4424 - mae: 2.4424 - mse: 20.9888\n",
      "Epoch 1: val_loss improved from inf to 0.81215, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 1s/step - loss: 2.4341 - mae: 2.4341 - mse: 20.8773 - val_loss: 0.8121 - val_mae: 0.8121 - val_mse: 0.9410 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.8424 - mae: 0.8424 - mse: 1.0976\n",
      "Epoch 2: val_loss improved from 0.81215 to 0.74701, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - loss: 0.8423 - mae: 0.8423 - mse: 1.0973 - val_loss: 0.7470 - val_mae: 0.7470 - val_mse: 0.8980 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.8038 - mae: 0.8038 - mse: 1.0109\n",
      "Epoch 3: val_loss improved from 0.74701 to 0.74029, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 1s/step - loss: 0.8037 - mae: 0.8037 - mse: 1.0107 - val_loss: 0.7403 - val_mae: 0.7403 - val_mse: 0.8753 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7968 - mae: 0.7968 - mse: 0.9999\n",
      "Epoch 4: val_loss improved from 0.74029 to 0.73566, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - loss: 0.7967 - mae: 0.7967 - mse: 0.9996 - val_loss: 0.7357 - val_mae: 0.7357 - val_mse: 0.8716 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7790 - mae: 0.7790 - mse: 0.9664\n",
      "Epoch 5: val_loss did not improve from 0.73566\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 1s/step - loss: 0.7789 - mae: 0.7789 - mse: 0.9662 - val_loss: 0.7426 - val_mae: 0.7426 - val_mse: 0.8531 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7593 - mae: 0.7593 - mse: 0.9272\n",
      "Epoch 6: val_loss improved from 0.73566 to 0.73508, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - loss: 0.7593 - mae: 0.7593 - mse: 0.9271 - val_loss: 0.7351 - val_mae: 0.7351 - val_mse: 0.8570 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7652 - mae: 0.7652 - mse: 0.9374\n",
      "Epoch 7: val_loss improved from 0.73508 to 0.72536, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - loss: 0.7651 - mae: 0.7651 - mse: 0.9372 - val_loss: 0.7254 - val_mae: 0.7254 - val_mse: 0.8224 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7544 - mae: 0.7544 - mse: 0.9226\n",
      "Epoch 8: val_loss improved from 0.72536 to 0.70948, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - loss: 0.7543 - mae: 0.7543 - mse: 0.9225 - val_loss: 0.7095 - val_mae: 0.7095 - val_mse: 0.8069 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7360 - mae: 0.7360 - mse: 0.8927\n",
      "Epoch 9: val_loss did not improve from 0.70948\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 1s/step - loss: 0.7359 - mae: 0.7359 - mse: 0.8926 - val_loss: 0.7149 - val_mae: 0.7149 - val_mse: 0.7904 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7210 - mae: 0.7210 - mse: 0.8535\n",
      "Epoch 10: val_loss improved from 0.70948 to 0.69001, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - loss: 0.7210 - mae: 0.7210 - mse: 0.8535 - val_loss: 0.6900 - val_mae: 0.6900 - val_mse: 0.7763 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7268 - mae: 0.7268 - mse: 0.8651\n",
      "Epoch 11: val_loss improved from 0.69001 to 0.67433, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - loss: 0.7267 - mae: 0.7267 - mse: 0.8650 - val_loss: 0.6743 - val_mae: 0.6743 - val_mse: 0.7596 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7168 - mae: 0.7168 - mse: 0.8572\n",
      "Epoch 12: val_loss improved from 0.67433 to 0.65736, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - loss: 0.7167 - mae: 0.7167 - mse: 0.8570 - val_loss: 0.6574 - val_mae: 0.6574 - val_mse: 0.7391 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.7016 - mae: 0.7016 - mse: 0.8273\n",
      "Epoch 13: val_loss did not improve from 0.65736\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - loss: 0.7015 - mae: 0.7015 - mse: 0.8272 - val_loss: 0.6698 - val_mae: 0.6698 - val_mse: 0.7334 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6780 - mae: 0.6780 - mse: 0.7840\n",
      "Epoch 14: val_loss improved from 0.65736 to 0.61472, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - loss: 0.6780 - mae: 0.6780 - mse: 0.7840 - val_loss: 0.6147 - val_mae: 0.6147 - val_mse: 0.6766 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6773 - mae: 0.6773 - mse: 0.7865\n",
      "Epoch 15: val_loss improved from 0.61472 to 0.59161, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - loss: 0.6773 - mae: 0.6773 - mse: 0.7865 - val_loss: 0.5916 - val_mae: 0.5916 - val_mse: 0.6882 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6634 - mae: 0.6634 - mse: 0.7766\n",
      "Epoch 16: val_loss did not improve from 0.59161\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - loss: 0.6633 - mae: 0.6633 - mse: 0.7765 - val_loss: 0.6526 - val_mae: 0.6526 - val_mse: 0.7005 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6783 - mae: 0.6783 - mse: 0.7812\n",
      "Epoch 17: val_loss improved from 0.59161 to 0.55350, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - loss: 0.6782 - mae: 0.6782 - mse: 0.7811 - val_loss: 0.5535 - val_mae: 0.5535 - val_mse: 0.6308 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6428 - mae: 0.6428 - mse: 0.7415\n",
      "Epoch 18: val_loss did not improve from 0.55350\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - loss: 0.6427 - mae: 0.6427 - mse: 0.7413 - val_loss: 0.5914 - val_mae: 0.5914 - val_mse: 0.6349 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6445 - mae: 0.6445 - mse: 0.7391\n",
      "Epoch 19: val_loss did not improve from 0.55350\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - loss: 0.6444 - mae: 0.6444 - mse: 0.7389 - val_loss: 0.5906 - val_mae: 0.5906 - val_mse: 0.6281 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6333 - mae: 0.6333 - mse: 0.7187\n",
      "Epoch 20: val_loss did not improve from 0.55350\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 1s/step - loss: 0.6332 - mae: 0.6332 - mse: 0.7185 - val_loss: 0.6323 - val_mae: 0.6323 - val_mse: 0.6632 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6239 - mae: 0.6239 - mse: 0.7040\n",
      "Epoch 21: val_loss did not improve from 0.55350\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - loss: 0.6238 - mae: 0.6238 - mse: 0.7038 - val_loss: 0.6276 - val_mae: 0.6276 - val_mse: 0.6552 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6425 - mae: 0.6425 - mse: 0.7090\n",
      "Epoch 22: val_loss improved from 0.55350 to 0.54754, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - loss: 0.6423 - mae: 0.6423 - mse: 0.7087 - val_loss: 0.5475 - val_mae: 0.5475 - val_mse: 0.5553 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.6034 - mae: 0.6034 - mse: 0.6568\n",
      "Epoch 23: val_loss improved from 0.54754 to 0.51286, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - loss: 0.6033 - mae: 0.6033 - mse: 0.6567 - val_loss: 0.5129 - val_mae: 0.5129 - val_mse: 0.5346 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.5859 - mae: 0.5859 - mse: 0.6341\n",
      "Epoch 24: val_loss did not improve from 0.51286\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 1s/step - loss: 0.5859 - mae: 0.5859 - mse: 0.6340 - val_loss: 0.5556 - val_mae: 0.5556 - val_mse: 0.5705 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.5786 - mae: 0.5786 - mse: 0.6273\n",
      "Epoch 25: val_loss did not improve from 0.51286\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - loss: 0.5785 - mae: 0.5785 - mse: 0.6271 - val_loss: 0.5309 - val_mae: 0.5309 - val_mse: 0.5118 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.5826 - mae: 0.5826 - mse: 0.6250\n",
      "Epoch 26: val_loss did not improve from 0.51286\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 1s/step - loss: 0.5825 - mae: 0.5825 - mse: 0.6249 - val_loss: 0.5168 - val_mae: 0.5168 - val_mse: 0.5197 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.5714 - mae: 0.5714 - mse: 0.6072\n",
      "Epoch 27: val_loss improved from 0.51286 to 0.50401, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - loss: 0.5713 - mae: 0.5713 - mse: 0.6070 - val_loss: 0.5040 - val_mae: 0.5040 - val_mse: 0.5086 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.5609 - mae: 0.5609 - mse: 0.5888\n",
      "Epoch 28: val_loss improved from 0.50401 to 0.46858, saving model to c:\\Users\\ThinkPad\\Desktop\\COSC2753_A2_MachineLearning/paddy_models/kfold_models/best_vit_age_model_fold_1.keras\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - loss: 0.5608 - mae: 0.5608 - mse: 0.5887 - val_loss: 0.4686 - val_mae: 0.4686 - val_mse: 0.4692 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m 94/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: 0.5353 - mae: 0.5353 - mse: 0.5638"
     ]
    }
   ],
   "source": [
    "# Perform k-fold training\n",
    "fold_results, fold_histories, ensemble_predictions = perform_kfold_training()\n",
    "\n",
    "# Analyze k-fold results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"K-Fold Cross Validation Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "mae_scores = [result['mae'] for result in fold_results]\n",
    "rmse_scores = [result['rmse'] for result in fold_results]\n",
    "\n",
    "print(f\"\\nMAE per fold: {mae_scores}\")\n",
    "print(f\"RMSE per fold: {rmse_scores}\")\n",
    "print(f\"\\nAverage MAE: {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "print(f\"Average RMSE: {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8415bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k-fold results\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "results_df.to_csv(HOME_PATH + 'kfold_results.csv', index=False)\n",
    "\n",
    "# Plot k-fold training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('K-Fold Training History', fontsize=16)\n",
    "\n",
    "# Plot loss\n",
    "axes[0, 0].set_title('Training Loss by Fold')\n",
    "for i, history in enumerate(fold_histories):\n",
    "    axes[0, 0].plot(history.history['loss'], label=f'Fold {i+1}', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss (MAE)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot validation loss\n",
    "axes[0, 1].set_title('Validation Loss by Fold')\n",
    "for i, history in enumerate(fold_histories):\n",
    "    axes[0, 1].plot(history.history['val_loss'], label=f'Fold {i+1}', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Validation Loss (MAE)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot MAE\n",
    "axes[1, 0].set_title('Training MAE by Fold')\n",
    "for i, history in enumerate(fold_histories):\n",
    "    axes[1, 0].plot(history.history['mae'], label=f'Fold {i+1}', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('MAE')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot validation MAE\n",
    "axes[1, 1].set_title('Validation MAE by Fold')\n",
    "for i, history in enumerate(fold_histories):\n",
    "    axes[1, 1].plot(history.history['val_mae'], label=f'Fold {i+1}', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Validation MAE')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(HOME_PATH + 'kfold_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot fold comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "folds = [f'Fold {i+1}' for i in range(k_folds)]\n",
    "x = np.arange(len(folds))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, mae_scores, width, label='MAE', alpha=0.8)\n",
    "plt.bar(x + width/2, rmse_scores, width, label='RMSE', alpha=0.8)\n",
    "\n",
    "plt.ylabel('Error (days)')\n",
    "plt.title('Performance Comparison Across Folds')\n",
    "plt.xticks(x, folds)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(HOME_PATH + 'kfold_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Generate ensemble predictions for test set\n",
    "def load_test_images():\n",
    "    test_data = []\n",
    "    test_ids = []\n",
    "    \n",
    "    test_path = HOME_PATH + 'test_images/'\n",
    "    for img_file in tqdm(os.listdir(test_path)):\n",
    "        if img_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(test_path, img_file)\n",
    "            image = np.array(Image.open(img_path).convert('RGB').resize((256, 256)))\n",
    "            test_data.append(image)\n",
    "            test_ids.append(img_file.split('.')[0])\n",
    "    \n",
    "    return np.array(test_data), test_ids\n",
    "\n",
    "# Load test images\n",
    "print(\"\\nLoading test images...\")\n",
    "test_images, test_ids = load_test_images()\n",
    "\n",
    "# Ensemble prediction\n",
    "print(\"\\nMaking ensemble predictions...\")\n",
    "all_predictions = []\n",
    "\n",
    "for model, age_mean, age_std in ensemble_predictions:\n",
    "    predictions_norm = model.predict(test_images, verbose=0)\n",
    "    predictions_original = predictions_norm.flatten() * age_std + age_mean\n",
    "    all_predictions.append(predictions_original)\n",
    "\n",
    "# Average predictions across folds\n",
    "ensemble_predictions_avg = np.mean(all_predictions, axis=0)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_id': test_ids,\n",
    "    'age': ensemble_predictions_avg.astype(int).astype(str)\n",
    "})\n",
    "\n",
    "# Save ensemble predictions\n",
    "submission_df.to_csv(HOME_PATH + 'age_predictions_kfold_ensemble.csv', index=False)\n",
    "\n",
    "print(f\"\\nEnsemble prediction statistics:\")\n",
    "print(f\"Min predicted age: {ensemble_predictions_avg.min():.2f} days\")\n",
    "print(f\"Max predicted age: {ensemble_predictions_avg.max():.2f} days\")\n",
    "print(f\"Mean predicted age: {ensemble_predictions_avg.mean():.2f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save individual fold predictions for analysis\n",
    "individual_predictions_df = pd.DataFrame({\n",
    "    'image_id': test_ids,\n",
    "    **{f'fold_{i+1}_prediction': pred for i, pred in enumerate(all_predictions)}\n",
    "})\n",
    "individual_predictions_df.to_csv(HOME_PATH + 'age_predictions_individual_folds.csv', index=False)\n",
    "\n",
    "# Analyze prediction variance across folds\n",
    "prediction_std = np.std(all_predictions, axis=0)\n",
    "prediction_variance_df = pd.DataFrame({\n",
    "    'image_id': test_ids,\n",
    "    'ensemble_prediction': ensemble_predictions_avg,\n",
    "    'prediction_std': prediction_std,\n",
    "    'coefficient_of_variation': prediction_std / ensemble_predictions_avg\n",
    "})\n",
    "prediction_variance_df.to_csv(HOME_PATH + 'prediction_variance_analysis.csv', index=False)\n",
    "\n",
    "print(f\"\\nPrediction variance statistics:\")\n",
    "print(f\"Average standard deviation across predictions: {prediction_std.mean():.2f}\")\n",
    "print(f\"Maximum standard deviation: {prediction_std.max():.2f}\")\n",
    "print(f\"Images with high prediction variance (std > 10): {sum(prediction_std > 10)}\")\n",
    "\n",
    "# Save age statistics (using average from all folds)\n",
    "age_stats = {\n",
    "    'mean': np.mean([result['age_mean'] for result in fold_results]),\n",
    "    'std': np.mean([result['age_std'] for result in fold_results])\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(HOME_PATH + 'age_stats_kfold.json', 'w') as f:\n",
    "    json.dump(age_stats, f)\n",
    "\n",
    "print(\"\\nK-fold cross-validation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
