{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3616d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4790f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "random.seed(45)\n",
    "tf.random.set_seed(45)\n",
    "np.random.seed(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f847341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants (same as in training script)\n",
    "image_size = 72\n",
    "patch_size = 6\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fe563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP helper function\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "# Define custom layers\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super(Patches, self).__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Patches, self).get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        patch_size = config.pop(\"patch_size\")\n",
    "        return cls(patch_size=patch_size, **config)\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super(PatchEncoder, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(PatchEncoder, self).get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\": self.projection_dim\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        num_patches = config.pop(\"num_patches\")\n",
    "        projection_dim = config.pop(\"projection_dim\")\n",
    "        return cls(num_patches=num_patches, projection_dim=projection_dim, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e64c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the ViT model\n",
    "def create_vit_regressor(input_images=None):\n",
    "    # Create data augmentation inside model\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.Normalization(),\n",
    "            layers.Resizing(image_size, image_size),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(factor=0.02),\n",
    "            layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "    \n",
    "    # Adapt normalization layer if input images are provided\n",
    "    if input_images is not None:\n",
    "        data_augmentation.layers[0].adapt(input_images)\n",
    "    \n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    # Augment data\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    \n",
    "    # Encode patches\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        \n",
    "        # Create a multi-head attention layer\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        \n",
    "        # Skip connection 1\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        \n",
    "        # Layer normalization 2\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        \n",
    "        # MLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        \n",
    "        # Skip connection 2\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    \n",
    "    # Add MLP\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    \n",
    "    # Output layer for regression (single neuron for age)\n",
    "    output = layers.Dense(1, activation='linear')(features)\n",
    "    \n",
    "    # Create the Keras model\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5987d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the ensemble models\n",
    "def load_ensemble_models(models_dir, k_folds=3):\n",
    "    ensemble_models = []\n",
    "    \n",
    "    # Load age statistics\n",
    "    with open(os.path.join(models_dir, 'age_stats_kfold.json'), 'r') as f:\n",
    "        age_stats = json.load(f)\n",
    "        average_age_mean = age_stats['mean']\n",
    "        average_age_std = age_stats['std']\n",
    "    \n",
    "    # For testing purposes, if no stats file exists, use these defaults\n",
    "    if not os.path.exists(os.path.join(models_dir, 'age_stats_kfold.json')):\n",
    "        print(\"Warning: Could not find age statistics file. Using default values.\")\n",
    "        average_age_mean = 64.0436244835207  # Example value, should be replaced with actual mean\n",
    "        average_age_std = 8.9582253420494    # Example value, should be replaced with actual std\n",
    "    \n",
    "    # Create and load each fold model\n",
    "    for fold in range(1, k_folds + 1):\n",
    "        # Create a fresh model\n",
    "        model = create_vit_regressor()\n",
    "        \n",
    "        # Compile model (not strictly necessary for inference but good practice)\n",
    "        optimizer = keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='mean_absolute_error',\n",
    "            metrics=['mae', 'mse']\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        weights_path = os.path.join(models_dir, f'paddy_models/kfold_models/best_vit_age_model_fold_{fold}.weights.h5')\n",
    "        \n",
    "        if os.path.exists(weights_path):\n",
    "            model.load_weights(weights_path)\n",
    "            print(f\"Loaded weights for fold {fold} from {weights_path}\")\n",
    "            \n",
    "            # Load individual fold stats if available, otherwise use average\n",
    "            # You could implement fold-specific stats if needed\n",
    "            fold_mean = average_age_mean\n",
    "            fold_std = average_age_std\n",
    "            \n",
    "            ensemble_models.append((model, fold_mean, fold_std))\n",
    "        else:\n",
    "            print(f\"Warning: Could not find weights for fold {fold} at {weights_path}\")\n",
    "    \n",
    "    if not ensemble_models:\n",
    "        raise FileNotFoundError(\"No model weights could be loaded. Please check the paths.\")\n",
    "        \n",
    "    return ensemble_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess images\n",
    "def preprocess_images(image_paths):\n",
    "    preprocessed_images = []\n",
    "    image_ids = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        if isinstance(img_path, str) and os.path.exists(img_path):\n",
    "            # Extract image id\n",
    "            img_id = Path(img_path).stem\n",
    "            image_ids.append(img_id)\n",
    "            \n",
    "            # Load and preprocess image\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = image.resize((256, 256))\n",
    "            image = np.array(image)\n",
    "            preprocessed_images.append(image)\n",
    "    \n",
    "    return np.array(preprocessed_images), image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions with the ensemble\n",
    "def predict_paddy_age(image_paths, ensemble_models):\n",
    "    # Preprocess images\n",
    "    preprocessed_images, image_ids = preprocess_images(image_paths)\n",
    "    \n",
    "    if len(preprocessed_images) == 0:\n",
    "        print(\"No valid images were provided for prediction.\")\n",
    "        return None\n",
    "    \n",
    "    # Make predictions with each model in the ensemble\n",
    "    all_predictions = []\n",
    "    \n",
    "    for model, age_mean, age_std in ensemble_models:\n",
    "        predictions_norm = model.predict(preprocessed_images, verbose=0)\n",
    "        print(f\"Predictions (normalized) for model: {predictions_norm.flatten()}\")\n",
    "        predictions_original = predictions_norm.flatten() * age_std + age_mean\n",
    "        all_predictions.append(predictions_original)\n",
    "    \n",
    "    # Average predictions across all models in the ensemble\n",
    "    ensemble_predictions = np.mean(all_predictions, axis=0)\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    results_df = pd.DataFrame({\n",
    "        'image_id': image_ids,\n",
    "        'predicted_age': ensemble_predictions,\n",
    "        'predicted_age_rounded': np.round(ensemble_predictions).astype(int)\n",
    "    })\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Function to create a submission file\n",
    "def create_submission(predictions_df, output_path):\n",
    "    submission_df = pd.DataFrame({\n",
    "        'image_id': predictions_df['image_id'],\n",
    "        'age': predictions_df['predicted_age_rounded'].astype(str)\n",
    "    })\n",
    "    \n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    print(f\"Submission file saved to {output_path}\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Main function to demonstrate usage\n",
    "def main():\n",
    "    # Set the path to your models directory\n",
    "    models_dir = os.getcwd()  # Adjust as needed\n",
    "    \n",
    "    # Load ensemble models\n",
    "    print(\"Loading ensemble models...\")\n",
    "    ensemble_models = load_ensemble_models(models_dir, k_folds=3)\n",
    "    \n",
    "    # Example: predict on test images\n",
    "    test_dir = os.path.join(models_dir, 'test_images')\n",
    "    \n",
    "    if os.path.exists(test_dir):\n",
    "        print(f\"Found test directory: {test_dir}\")\n",
    "        # Get all image files from the test directory\n",
    "        test_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) \n",
    "                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        if test_images:\n",
    "            print(f\"Making predictions on {len(test_images)} test images...\")\n",
    "            predictions_df = predict_paddy_age(test_images, ensemble_models)\n",
    "            \n",
    "            # Create submission file\n",
    "            output_path = os.path.join(models_dir, 'age_predictions_submission.csv')\n",
    "            create_submission(predictions_df, output_path)\n",
    "        else:\n",
    "            print(\"No image files found in the test directory.\")\n",
    "    else:\n",
    "        print(f\"Test directory not found: {test_dir}\")\n",
    "        print(\"Please provide the path to your test images to make predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c03489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
