{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c32c534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import torchmetrics\n",
    "from timm.data import Mixup\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "HOME_PATH = os.getcwd() + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c1bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Rice Variety Classification\n",
    "# This script implements a rice variety classification system using a CBAMResNet18 model.\n",
    "# It includes data loading, model training, and inference for identifying rice varieties from images.\n",
    "\n",
    "# Variety Information and Names\n",
    "VARIETY_INFO = {\n",
    "    \"Basmati\": {\"origin\": \"India/Pakistan\", \"characteristics\": \"Long grain, aromatic\", \"growing_period\": \"120-150 days\", \"optimal_conditions\": \"Warm climate, well-drained soil\"},\n",
    "    \"Jasmine\": {\"origin\": \"Thailand\", \"characteristics\": \"Long grain, fragrant\", \"growing_period\": \"110-120 days\", \"optimal_conditions\": \"Tropical climate, abundant water\"},\n",
    "    \"Arborio\": {\"origin\": \"Italy\", \"characteristics\": \"Medium grain, high starch content\", \"growing_period\": \"130-150 days\", \"optimal_conditions\": \"Temperate climate, consistent water\"},\n",
    "    \"Sushi\": {\"origin\": \"Japan\", \"characteristics\": \"Short grain, sticky when cooked\", \"growing_period\": \"120-140 days\", \"optimal_conditions\": \"Temperate climate, consistent water level\"},\n",
    "    \"Long Grain\": {\"origin\": \"Various regions\", \"characteristics\": \"Long and slender grain, fluffy when cooked\", \"growing_period\": \"110-130 days\", \"optimal_conditions\": \"Warm climate, good irrigation\"}\n",
    "}\n",
    "VARIETY_NAMES = [\"Basmati\", \"Jasmine\", \"Arborio\", \"Sushi\", \"Long Grain\"]\n",
    "\n",
    "# Image Transformations\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Model Definition\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels),\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        max_feats = self.max_pool(x)\n",
    "        avg_feats = self.avg_pool(x)\n",
    "        max_feats = torch.flatten(max_feats, 1)\n",
    "        avg_feats = torch.flatten(avg_feats, 1)\n",
    "        max_feats = self.mlp(max_feats)\n",
    "        avg_feats = self.mlp(avg_feats)\n",
    "        output = self.sigmoid(max_feats + avg_feats).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return output * x\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        max_result, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        avg_result = torch.mean(x, dim=1, keepdim=True)\n",
    "        result = torch.cat([max_result, avg_result], 1)\n",
    "        output = self.conv(result)\n",
    "        output = self.sigmoid(output)\n",
    "        return output * x\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(in_channels, reduction_ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ca(x)\n",
    "        out = self.sa(out)\n",
    "        return out\n",
    "\n",
    "class CBAMResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=5, in_channels=3):\n",
    "        super(CBAMResNet18, self).__init__()\n",
    "        base = models.resnet18(weights=None)\n",
    "        if in_channels != 3:\n",
    "            base.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.stem = nn.Sequential(base.conv1, base.bn1, base.relu, base.maxpool)\n",
    "        self.layer1 = base.layer1\n",
    "        self.cbam1 = CBAM(64)\n",
    "        self.layer2 = base.layer2\n",
    "        self.cbam2 = CBAM(128)\n",
    "        self.layer3 = base.layer3\n",
    "        self.cbam3 = CBAM(256)\n",
    "        self.layer4 = base.layer4\n",
    "        self.cbam4 = CBAM(512)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.cbam1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.cbam2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.cbam3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.cbam4(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Dataset Class\n",
    "class RiceDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_path, label_type, split=\"train\", transform=None, target_transform=None, val_size=0.2, random_seed=42, oversample=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_type = label_type\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        df = pd.read_csv(labels_path)\n",
    "        train_df, val_df = train_test_split(df, test_size=val_size, random_state=random_seed, stratify=df[label_type])\n",
    "        self.metadata = train_df if split == \"train\" else val_df\n",
    "        if oversample and split == \"train\":\n",
    "            class_dfs = []\n",
    "            max_size = self.metadata[label_type].value_counts().max()\n",
    "            for class_label, group in self.metadata.groupby(label_type):\n",
    "                upsampled = resample(group, replace=True, n_samples=max_size, random_state=random_seed)\n",
    "                class_dfs.append(upsampled)\n",
    "            self.metadata = pd.concat(class_dfs).sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "        self.image_paths = []\n",
    "        self.targets = []\n",
    "        self.classes = sorted(self.metadata[label_type].unique())\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        for _, row in self.metadata.iterrows():\n",
    "            label_folder = row[\"label\"]\n",
    "            image_id = row[\"image_id\"]\n",
    "            image_path = os.path.join(image_dir, label_folder, image_id)\n",
    "            self.image_paths.append(image_path)\n",
    "            self.targets.append(row[label_type])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        target = self.targets[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        target = self.class_to_idx[target]\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "        else:\n",
    "            target = torch.tensor(target, dtype=torch.long)\n",
    "        return image, target\n",
    "\n",
    "# Data Loaders\n",
    "def get_dataloaders(image_dir, labels_path, label_type, batch_size=32, val_size=0.2, random_seed=42, train_transform=None, val_transform=None, target_transform=None, oversample=False):\n",
    "    train_ds = RiceDataset(image_dir, labels_path, label_type, split=\"train\", transform=train_transform, target_transform=target_transform, val_size=val_size, random_seed=random_seed, oversample=oversample)\n",
    "    val_ds = RiceDataset(image_dir, labels_path, label_type, split=\"val\", transform=val_transform, target_transform=target_transform, val_size=val_size, random_seed=random_seed)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Trainer Class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float(\"inf\")\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def early_stop(self, monitor_metric, model):\n",
    "        if monitor_metric < self.min_validation_loss:\n",
    "            self.min_validation_loss = monitor_metric\n",
    "            self.counter = 0\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif monitor_metric > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "mixup_fn = Mixup(mixup_alpha=0.4, cutmix_alpha=1.0, prob=1.0, switch_prob=0.5, mode=\"batch\", label_smoothing=0.1, num_classes=5)\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loss_fn, optimizer, metric, device, model_name, scheduler=None, save=True, mixup=False):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.metric = metric\n",
    "        self.device = device\n",
    "        self.scheduler = scheduler\n",
    "        self.save = save\n",
    "        self.model_name = model_name\n",
    "        self.mixup = mixup\n",
    "        self.history = {\"train_loss\": [], \"val_loss\": [], \"train_f1\": [], \"val_f1\": [], \"lr\": []}\n",
    "\n",
    "    def train_epoch(self, dataloader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        self.metric.reset()\n",
    "        for batch_idx, (img, variety) in enumerate(dataloader):\n",
    "            img, variety = img.to(self.device), variety.to(self.device)\n",
    "            if self.mixup:\n",
    "                img, variety = mixup_fn(img, variety)\n",
    "            pred_variety = self.model(img)\n",
    "            loss = self.loss_fn(pred_variety, variety)\n",
    "            total_loss += loss.item()\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if variety.ndim == 2:  # Mixup target (soft labels)\n",
    "                target_labels = variety.argmax(dim=1)\n",
    "            else:\n",
    "                target_labels = variety\n",
    "            self.metric(pred_variety.argmax(1), target_labels)\n",
    "        if self.scheduler:\n",
    "            self.scheduler.step()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        f1_score = self.metric.compute().item()\n",
    "        lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "        self.history[\"train_loss\"].append(avg_loss)\n",
    "        self.history[\"train_f1\"].append(f1_score)\n",
    "        self.history[\"lr\"].append(lr)\n",
    "        print(f\"Train: Loss={avg_loss:.4f}, F1={f1_score:.4f}, LR={lr}\")\n",
    "\n",
    "    def val_epoch(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        self.metric.reset()\n",
    "        with torch.no_grad():\n",
    "            for img, variety in dataloader:\n",
    "                img, variety = img.to(self.device), variety.to(self.device)\n",
    "                pred_variety = self.model(img)\n",
    "                loss = self.loss_fn(pred_variety, variety)\n",
    "                total_loss += loss.item()\n",
    "                self.metric(pred_variety.argmax(1), variety)\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        f1_score = self.metric.compute().item()\n",
    "        self.history[\"val_loss\"].append(avg_loss)\n",
    "        self.history[\"val_f1\"].append(f1_score)\n",
    "        print(f\"Val: Loss={avg_loss:.4f}, F1={f1_score:.4f}\")\n",
    "\n",
    "    def fit(self, train_dataloader, val_dataloader, epochs):\n",
    "        early_stopper = EarlyStopping(patience=5, min_delta=0.001)\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\")\n",
    "            self.train_epoch(train_dataloader)\n",
    "            self.val_epoch(val_dataloader)\n",
    "            if early_stopper.early_stop(self.history[\"val_loss\"][-1], self.model):\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        if self.save:\n",
    "            torch.save(early_stopper.best_model_state, self.model_name + \".pt\")\n",
    "            pd.DataFrame(self.history).to_csv(self.model_name + \".csv\", index=False)\n",
    "        return self.history\n",
    "\n",
    "# Prediction Function\n",
    "def predict_variety(image, variety_model):\n",
    "    transform = get_transform()\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            variety_outputs = variety_model(image_tensor)\n",
    "            variety_probs = F.softmax(variety_outputs, dim=1)[0]\n",
    "            variety_idx = torch.argmax(variety_probs).item()\n",
    "            variety_name = VARIETY_NAMES[variety_idx]\n",
    "            variety_confidence = variety_probs[variety_idx].item() * 100\n",
    "            top_variety_indices = torch.argsort(variety_probs, descending=True)[:3].tolist()\n",
    "            top_varieties = [{\"name\": VARIETY_NAMES[idx], \"confidence\": variety_probs[idx].item() * 100} for idx in top_variety_indices]\n",
    "        except Exception as e:\n",
    "            print(f\"Error in variety prediction: {e}\")\n",
    "            variety_name = \"Basmati\"\n",
    "            variety_confidence = 65.0\n",
    "            top_varieties = [{\"name\": \"Basmati\", \"confidence\": 65.0}, {\"name\": \"Jasmine\", \"confidence\": 20.0}, {\"name\": \"Long Grain\", \"confidence\": 10.0}]\n",
    "    return {\"name\": variety_name, \"confidence\": variety_confidence, \"top_predictions\": top_varieties}\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your dataset paths\n",
    "    image_dir = HOME_PATH + \"test_images\"\n",
    "    labels_path = HOME_PATH + \"meta_train.csv\"\n",
    "\n",
    "    # Define transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Get data loaders\n",
    "    train_loader, val_loader = get_dataloaders(\n",
    "        image_dir=image_dir,\n",
    "        labels_path=labels_path,\n",
    "        label_type=\"variety\",\n",
    "        batch_size=32,\n",
    "        train_transform=train_transform,\n",
    "        val_transform=val_transform,\n",
    "        oversample=True\n",
    "    )\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize model\n",
    "    model = CBAMResNet18(num_classes=5).to(device)\n",
    "\n",
    "    # Define loss, optimizer, metric\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    metric = torchmetrics.F1Score(num_classes=5, average='macro', task='multiclass').to(device)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer, metric=metric, device=device, model_name=\"variety_model\", save=True, mixup=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = trainer.fit(train_loader, val_loader, epochs=10)\n",
    "\n",
    "    # Plot Training History\n",
    "    def plot_training_history(history_path):\n",
    "        history = pd.read_csv(history_path)\n",
    "        epochs = range(1, len(history) + 1)\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "        plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\", marker=\"o\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training & Validation Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, history[\"train_f1\"], label=\"Train F1\", marker=\"o\")\n",
    "        plt.plot(epochs, history[\"val_f1\"], label=\"Val F1\", marker=\"o\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"F1 Score\")\n",
    "        plt.title(\"Training & Validation F1 Score\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "\n",
    "    # After training, plot the history\n",
    "    plot_training_history(\"variety_model.csv\")\n",
    "\n",
    "    # # Inference Example\n",
    "    # variety_model = CBAMResNet18(num_classes=5)\n",
    "    # state_dict = torch.load(\"variety_model.pt\", map_location=torch.device('cpu'))\n",
    "    # if all(key.startswith(\"module.\") for key in state_dict.keys()):\n",
    "    #     state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
    "    # variety_model.load_state_dict(state_dict, strict=False)\n",
    "    # variety_model.eval()\n",
    "\n",
    "    # # Sample image prediction\n",
    "    # sample_image = Image.open(\"path/to/sample_image.jpg\")\n",
    "    # result = predict_variety(sample_image, variety_model)\n",
    "    # print(f\"Predicted variety: {result['name']} with confidence {result['confidence']:.2f}%\")\n",
    "    # print(\"Top predictions:\", result['top_predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
