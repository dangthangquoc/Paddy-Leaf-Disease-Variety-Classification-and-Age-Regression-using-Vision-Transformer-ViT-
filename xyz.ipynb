{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ae7131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10407 files belonging to 10 classes.\n",
      "Using 8326 files for training.\n",
      "Found 10407 files belonging to 10 classes.\n",
      "Using 2081 files for validation.\n",
      "Found 3469 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import os, gc, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- PATH & HYPERPARAMS ---\n",
    "HOME = os.getcwd() + \"/\"\n",
    "IMG_SIZE   = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES= 10\n",
    "AUTOTUNE   = tf.data.AUTOTUNE\n",
    "\n",
    "# --- LOAD DATASETS ---\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    HOME + \"train_images\", validation_split=0.2, subset=\"training\",\n",
    "    seed=123, image_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    HOME + \"train_images\", validation_split=0.2, subset=\"validation\",\n",
    "    seed=123, image_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    HOME + \"test_images\", label_mode=None,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "# --- PREPROCESS & AUGMENTATION ---\n",
    "rescale = layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x,y: (rescale(x),y), num_parallel_calls=AUTOTUNE)\n",
    "val_ds   = val_ds.map(lambda x,y: (rescale(x),y), num_parallel_calls=AUTOTUNE)\n",
    "test_ds  = test_ds.map(lambda x: rescale(x),    num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomTranslation(0.1,0.1)\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# --- CLASS WEIGHT & OVERSAMPLE ---\n",
    "labels = np.concatenate([y.numpy() for x,y in train_ds])\n",
    "counts = np.bincount(labels)\n",
    "class_weight = dict(enumerate(\n",
    "    compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "))\n",
    "train_unbatched = train_ds.unbatch()\n",
    "def oversample(ds, counts):\n",
    "    parts = []\n",
    "    m = counts.max()\n",
    "    for cid, c in enumerate(counts):\n",
    "        d = ds.filter(lambda x, y: tf.reduce_all(tf.equal(y, cid))).repeat(int(np.ceil(m/c)))\n",
    "        d = d.take(m)  # Lấy chính xác m mẫu cho mỗi lớp\n",
    "        parts.append(d)\n",
    "    return tf.data.Dataset.sample_from_datasets(parts, seed=123).take(m * len(counts))  # Lấy m * NUM_CLASSES mẫu\n",
    "overs = oversample(train_unbatched, counts)\n",
    "balanced_train = (overs\n",
    "    .map(lambda x,y: (data_augmentation(x,True), y), num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE).shuffle(1000).prefetch(AUTOTUNE)\n",
    ")\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "# --- MODEL ---\n",
    "base = EfficientNetB0(include_top=False, weights=None, input_shape=(*IMG_SIZE,3))\n",
    "x = base.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(224, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "out = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base.input, outputs=out)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# --- CALLBACKS ---\n",
    "class PrintValMetrics(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch+1}: val_loss = {logs['val_loss']:.4f}, val_accuracy = {logs['val_accuracy']:.4f}\")\n",
    "\n",
    "early = EarlyStopping(patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=3,\n",
    "                           min_lr=1e-5, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "print_val = PrintValMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451e6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "    875/Unknown - 994s 1s/step - loss: 6.0014 - accuracy: 0.1586\n",
      "Epoch 1: val_loss improved from inf to 3.61416, saving model to best_model.keras\n",
      "Epoch 1: val_loss = 3.6142, val_accuracy = 0.0750\n",
      "875/875 [==============================] - 1020s 1s/step - loss: 6.0014 - accuracy: 0.1586 - val_loss: 3.6142 - val_accuracy: 0.0750 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 3.0295 - accuracy: 0.2189\n",
      "Epoch 2: val_loss improved from 3.61416 to 3.06397, saving model to best_model.keras\n",
      "Epoch 2: val_loss = 3.0640, val_accuracy = 0.1216\n",
      "875/875 [==============================] - 988s 1s/step - loss: 3.0295 - accuracy: 0.2189 - val_loss: 3.0640 - val_accuracy: 0.1216 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 2.5189 - accuracy: 0.2590\n",
      "Epoch 3: val_loss improved from 3.06397 to 2.45156, saving model to best_model.keras\n",
      "Epoch 3: val_loss = 2.4516, val_accuracy = 0.1451\n",
      "875/875 [==============================] - 987s 1s/step - loss: 2.5189 - accuracy: 0.2590 - val_loss: 2.4516 - val_accuracy: 0.1451 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 2.4946 - accuracy: 0.2673\n",
      "Epoch 4: val_loss did not improve from 2.45156\n",
      "Epoch 4: val_loss = 3.0800, val_accuracy = 0.0750\n",
      "875/875 [==============================] - 984s 1s/step - loss: 2.4946 - accuracy: 0.2673 - val_loss: 3.0800 - val_accuracy: 0.0750 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 2.1852 - accuracy: 0.3275\n",
      "Epoch 5: val_loss improved from 2.45156 to 2.25800, saving model to best_model.keras\n",
      "Epoch 5: val_loss = 2.2580, val_accuracy = 0.1523\n",
      "875/875 [==============================] - 990s 1s/step - loss: 2.1852 - accuracy: 0.3275 - val_loss: 2.2580 - val_accuracy: 0.1523 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 2.3651 - accuracy: 0.3053\n",
      "Epoch 6: val_loss did not improve from 2.25800\n",
      "Epoch 6: val_loss = 2.3493, val_accuracy = 0.1062\n",
      "875/875 [==============================] - 989s 1s/step - loss: 2.3651 - accuracy: 0.3053 - val_loss: 2.3493 - val_accuracy: 0.1062 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 2.3463 - accuracy: 0.2941\n",
      "Epoch 7: val_loss did not improve from 2.25800\n",
      "Epoch 7: val_loss = 2.4057, val_accuracy = 0.0995\n",
      "875/875 [==============================] - 1008s 1s/step - loss: 2.3463 - accuracy: 0.2941 - val_loss: 2.4057 - val_accuracy: 0.0995 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 2.3035 - accuracy: 0.2904\n",
      "Epoch 8: val_loss improved from 2.25800 to 2.21734, saving model to best_model.keras\n",
      "Epoch 8: val_loss = 2.2173, val_accuracy = 0.1874\n",
      "875/875 [==============================] - 1018s 1s/step - loss: 2.3035 - accuracy: 0.2904 - val_loss: 2.2173 - val_accuracy: 0.1874 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 2.0115 - accuracy: 0.3627\n",
      "Epoch 9: val_loss did not improve from 2.21734\n",
      "Epoch 9: val_loss = 3.3464, val_accuracy = 0.2018\n",
      "875/875 [==============================] - 1029s 1s/step - loss: 2.0115 - accuracy: 0.3627 - val_loss: 3.3464 - val_accuracy: 0.2018 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 1.7341 - accuracy: 0.4272\n",
      "Epoch 10: val_loss improved from 2.21734 to 2.02500, saving model to best_model.keras\n",
      "Epoch 10: val_loss = 2.0250, val_accuracy = 0.2705\n",
      "875/875 [==============================] - 1023s 1s/step - loss: 1.7341 - accuracy: 0.4272 - val_loss: 2.0250 - val_accuracy: 0.2705 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 1.6538 - accuracy: 0.4505\n",
      "Epoch 11: val_loss did not improve from 2.02500\n",
      "Epoch 11: val_loss = 2.2350, val_accuracy = 0.2758\n",
      "875/875 [==============================] - 972s 1s/step - loss: 1.6538 - accuracy: 0.4505 - val_loss: 2.2350 - val_accuracy: 0.2758 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 1.4945 - accuracy: 0.5059\n",
      "Epoch 12: val_loss did not improve from 2.02500\n",
      "Epoch 12: val_loss = 2.1184, val_accuracy = 0.2778\n",
      "875/875 [==============================] - 974s 1s/step - loss: 1.4945 - accuracy: 0.5059 - val_loss: 2.1184 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 1.3542 - accuracy: 0.5548\n",
      "Epoch 13: val_loss improved from 2.02500 to 1.98631, saving model to best_model.keras\n",
      "Epoch 13: val_loss = 1.9863, val_accuracy = 0.3758\n",
      "875/875 [==============================] - 983s 1s/step - loss: 1.3542 - accuracy: 0.5548 - val_loss: 1.9863 - val_accuracy: 0.3758 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 1.3707 - accuracy: 0.5604\n",
      "Epoch 14: val_loss did not improve from 1.98631\n",
      "Epoch 14: val_loss = 2.1716, val_accuracy = 0.3421\n",
      "875/875 [==============================] - 1023s 1s/step - loss: 1.3707 - accuracy: 0.5604 - val_loss: 2.1716 - val_accuracy: 0.3421 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 1.1868 - accuracy: 0.6094\n",
      "Epoch 15: val_loss improved from 1.98631 to 1.64866, saving model to best_model.keras\n",
      "Epoch 15: val_loss = 1.6487, val_accuracy = 0.4354\n",
      "875/875 [==============================] - 1054s 1s/step - loss: 1.1868 - accuracy: 0.6094 - val_loss: 1.6487 - val_accuracy: 0.4354 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 1.1069 - accuracy: 0.6450\n",
      "Epoch 16: val_loss did not improve from 1.64866\n",
      "Epoch 16: val_loss = 1.7806, val_accuracy = 0.4474\n",
      "875/875 [==============================] - 1085s 1s/step - loss: 1.1069 - accuracy: 0.6450 - val_loss: 1.7806 - val_accuracy: 0.4474 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 1.0292 - accuracy: 0.6648\n",
      "Epoch 17: val_loss improved from 1.64866 to 1.61299, saving model to best_model.keras\n",
      "Epoch 17: val_loss = 1.6130, val_accuracy = 0.4897\n",
      "875/875 [==============================] - 1135s 1s/step - loss: 1.0292 - accuracy: 0.6648 - val_loss: 1.6130 - val_accuracy: 0.4897 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.9513 - accuracy: 0.6929\n",
      "Epoch 18: val_loss improved from 1.61299 to 1.58674, saving model to best_model.keras\n",
      "Epoch 18: val_loss = 1.5867, val_accuracy = 0.5036\n",
      "875/875 [==============================] - 1091s 1s/step - loss: 0.9513 - accuracy: 0.6929 - val_loss: 1.5867 - val_accuracy: 0.5036 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.9720 - accuracy: 0.6881\n",
      "Epoch 19: val_loss improved from 1.58674 to 1.52216, saving model to best_model.keras\n",
      "Epoch 19: val_loss = 1.5222, val_accuracy = 0.5041\n",
      "875/875 [==============================] - 1046s 1s/step - loss: 0.9720 - accuracy: 0.6881 - val_loss: 1.5222 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.8591 - accuracy: 0.7292\n",
      "Epoch 20: val_loss did not improve from 1.52216\n",
      "Epoch 20: val_loss = 1.8793, val_accuracy = 0.4234\n",
      "875/875 [==============================] - 1184s 1s/step - loss: 0.8591 - accuracy: 0.7292 - val_loss: 1.8793 - val_accuracy: 0.4234 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.8192 - accuracy: 0.7407\n",
      "Epoch 21: val_loss did not improve from 1.52216\n",
      "Epoch 21: val_loss = 2.0589, val_accuracy = 0.4402\n",
      "875/875 [==============================] - 1201s 1s/step - loss: 0.8192 - accuracy: 0.7407 - val_loss: 2.0589 - val_accuracy: 0.4402 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.7810 - accuracy: 0.7462\n",
      "Epoch 22: val_loss improved from 1.52216 to 1.37288, saving model to best_model.keras\n",
      "Epoch 22: val_loss = 1.3729, val_accuracy = 0.5867\n",
      "875/875 [==============================] - 998s 1s/step - loss: 0.7810 - accuracy: 0.7462 - val_loss: 1.3729 - val_accuracy: 0.5867 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.7670\n",
      "Epoch 23: val_loss did not improve from 1.37288\n",
      "Epoch 23: val_loss = 1.6601, val_accuracy = 0.5147\n",
      "875/875 [==============================] - 966s 1s/step - loss: 0.7438 - accuracy: 0.7670 - val_loss: 1.6601 - val_accuracy: 0.5147 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.7773\n",
      "Epoch 24: val_loss did not improve from 1.37288\n",
      "Epoch 24: val_loss = 1.6125, val_accuracy = 0.5296\n",
      "875/875 [==============================] - 970s 1s/step - loss: 0.6925 - accuracy: 0.7773 - val_loss: 1.6125 - val_accuracy: 0.5296 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.6530 - accuracy: 0.7931\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.37288\n",
      "Epoch 25: val_loss = 1.6396, val_accuracy = 0.5276\n",
      "875/875 [==============================] - 998s 1s/step - loss: 0.6530 - accuracy: 0.7931 - val_loss: 1.6396 - val_accuracy: 0.5276 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.8400\n",
      "Epoch 26: val_loss improved from 1.37288 to 1.25343, saving model to best_model.keras\n",
      "Epoch 26: val_loss = 1.2534, val_accuracy = 0.6237\n",
      "875/875 [==============================] - 1015s 1s/step - loss: 0.4963 - accuracy: 0.8400 - val_loss: 1.2534 - val_accuracy: 0.6237 - lr: 3.0000e-04\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8638\n",
      "Epoch 27: val_loss did not improve from 1.25343\n",
      "Epoch 27: val_loss = 1.2879, val_accuracy = 0.6204\n",
      "875/875 [==============================] - 1029s 1s/step - loss: 0.4246 - accuracy: 0.8638 - val_loss: 1.2879 - val_accuracy: 0.6204 - lr: 3.0000e-04\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.4010 - accuracy: 0.8728\n",
      "Epoch 28: val_loss improved from 1.25343 to 1.23145, saving model to best_model.keras\n",
      "Epoch 28: val_loss = 1.2315, val_accuracy = 0.6247\n",
      "875/875 [==============================] - 1057s 1s/step - loss: 0.4010 - accuracy: 0.8728 - val_loss: 1.2315 - val_accuracy: 0.6247 - lr: 3.0000e-04\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8766\n",
      "Epoch 29: val_loss did not improve from 1.23145\n",
      "Epoch 29: val_loss = 1.3763, val_accuracy = 0.6079\n",
      "875/875 [==============================] - 1076s 1s/step - loss: 0.3779 - accuracy: 0.8766 - val_loss: 1.3763 - val_accuracy: 0.6079 - lr: 3.0000e-04\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.8850\n",
      "Epoch 30: val_loss did not improve from 1.23145\n",
      "Epoch 30: val_loss = 1.3215, val_accuracy = 0.6353\n",
      "875/875 [==============================] - 1324s 1s/step - loss: 0.3549 - accuracy: 0.8850 - val_loss: 1.3215 - val_accuracy: 0.6353 - lr: 3.0000e-04\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8901\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.23145\n",
      "Epoch 31: val_loss = 1.4008, val_accuracy = 0.5949\n",
      "875/875 [==============================] - 1279s 1s/step - loss: 0.3441 - accuracy: 0.8901 - val_loss: 1.4008 - val_accuracy: 0.5949 - lr: 3.0000e-04\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.9049\n",
      "Epoch 32: val_loss did not improve from 1.23145\n",
      "Epoch 32: val_loss = 1.2578, val_accuracy = 0.6367\n",
      "875/875 [==============================] - 1560s 2s/step - loss: 0.3033 - accuracy: 0.9049 - val_loss: 1.2578 - val_accuracy: 0.6367 - lr: 9.0000e-05\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.9109\n",
      "Epoch 33: val_loss did not improve from 1.23145\n",
      "Epoch 33: val_loss = 1.2547, val_accuracy = 0.6406\n",
      "875/875 [==============================] - 1360s 1s/step - loss: 0.2769 - accuracy: 0.9109 - val_loss: 1.2547 - val_accuracy: 0.6406 - lr: 9.0000e-05\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.9104\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.23145\n",
      "Epoch 34: val_loss = 1.2713, val_accuracy = 0.6348\n",
      "875/875 [==============================] - 1283s 1s/step - loss: 0.2777 - accuracy: 0.9104 - val_loss: 1.2713 - val_accuracy: 0.6348 - lr: 9.0000e-05\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.9166\n",
      "Epoch 35: val_loss did not improve from 1.23145\n",
      "Epoch 35: val_loss = 1.2687, val_accuracy = 0.6300\n",
      "875/875 [==============================] - 1459s 2s/step - loss: 0.2691 - accuracy: 0.9166 - val_loss: 1.2687 - val_accuracy: 0.6300 - lr: 2.7000e-05\n",
      "Epoch 36/100\n"
     ]
    }
   ],
   "source": [
    "# --- FIT ---\n",
    "history = model.fit(\n",
    "    balanced_train,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    callbacks=[early, reduce, checkpoint, print_val],\n",
    "    verbose=1,  # Hiển thị progress bar\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOAD BEST WEIGHTS BEFORE PREDICT ---\n",
    "model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "\n",
    "# --- PREDICT & SUBMIT ---\n",
    "preds = model.predict(test_ds).argmax(axis=1)\n",
    "names = ['bacterial_leaf_blight','bacterial_leaf_streak','bacterial_panicle_blight',\n",
    "         'blast','brown_spot','dead_heart','downy_mildew','hispa','normal','tungro']\n",
    "submission = pd.DataFrame({\n",
    "    \"image_id\":[os.path.basename(p) for p in test_ds.file_paths],\n",
    "    \"label\":[names[i] for i in preds]\n",
    "})\n",
    "submission.to_csv(\"sample_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
