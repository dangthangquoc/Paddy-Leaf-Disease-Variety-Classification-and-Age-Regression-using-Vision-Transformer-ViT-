{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- PATH & HYPERPARAMS ---\n",
    "HOME = os.getcwd() + \"/\"\n",
    "IMG_SIZE   = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES= 10\n",
    "AUTOTUNE   = tf.data.AUTOTUNE\n",
    "\n",
    "# --- LOAD DATASETS ---\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    HOME + \"train_images\", validation_split=0.2, subset=\"training\",\n",
    "    seed=123, image_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    HOME + \"train_images\", validation_split=0.2, subset=\"validation\",\n",
    "    seed=123, image_size=IMG_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    HOME + \"test_images\", label_mode=None,\n",
    "    image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "# --- PREPROCESS & AUGMENTATION ---\n",
    "rescale = layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x,y: (rescale(x),y), num_parallel_calls=AUTOTUNE)\n",
    "val_ds   = val_ds.map(lambda x,y: (rescale(x),y), num_parallel_calls=AUTOTUNE)\n",
    "test_ds  = test_ds.map(lambda x: rescale(x),    num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),  # Tăng rotation\n",
    "    layers.RandomZoom(0.2),     # Tăng zoom\n",
    "    layers.RandomTranslation(0.2, 0.2),  # Tăng translation\n",
    "    layers.RandomContrast(0.2),  # Thêm contrast\n",
    "    layers.RandomBrightness(0.2)  # Thêm brightness\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# --- CLASS WEIGHT & OVERSAMPLE ---\n",
    "labels = np.concatenate([y.numpy() for x,y in train_ds])\n",
    "counts = np.bincount(labels)\n",
    "class_weight = dict(enumerate(\n",
    "    compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "))\n",
    "train_unbatched = train_ds.unbatch()\n",
    "def oversample(ds, counts):\n",
    "    parts = []\n",
    "    m = counts.max()\n",
    "    for cid, c in enumerate(counts):\n",
    "        d = ds.filter(lambda x, y: tf.reduce_all(tf.equal(y, cid))).repeat(int(np.ceil(m/c)))\n",
    "        d = d.take(m)  # Lấy chính xác m mẫu cho mỗi lớp\n",
    "        parts.append(d)\n",
    "    return tf.data.Dataset.sample_from_datasets(parts, seed=123).take(m * len(counts))  # Lấy m * NUM_CLASSES mẫu\n",
    "overs = oversample(train_unbatched, counts)\n",
    "balanced_train = (overs\n",
    "    .map(lambda x,y: (data_augmentation(x,True), y), num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE).shuffle(1000).prefetch(AUTOTUNE)\n",
    ")\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "# --- MODEL ---\n",
    "base = EfficientNetB0(include_top=False, weights=None, input_shape=(*IMG_SIZE,3))\n",
    "x = base.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)  \n",
    "x = layers.Dense(224, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "out = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base.input, outputs=out)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# --- CALLBACKS ---\n",
    "class PrintValMetrics(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch+1}: val_loss = {logs['val_loss']:.4f}, val_accuracy = {logs['val_accuracy']:.4f}\")\n",
    "\n",
    "early = EarlyStopping(patience=5, restore_best_weights=True, verbose=1)\n",
    "reduce = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=2,\n",
    "                           min_lr=1e-5, verbose=1)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "print_val = PrintValMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def89a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FIT ---\n",
    "history = model.fit(\n",
    "    balanced_train,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    callbacks=[early, reduce, checkpoint, print_val],\n",
    "    verbose=1,  # Hiển thị progress bar\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOAD BEST WEIGHTS BEFORE PREDICT ---\n",
    "model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "\n",
    "# --- PREDICT & SUBMIT ---\n",
    "preds = model.predict(test_ds).argmax(axis=1)\n",
    "names = ['bacterial_leaf_blight','bacterial_leaf_streak','bacterial_panicle_blight',\n",
    "         'blast','brown_spot','dead_heart','downy_mildew','hispa','normal','tungro']\n",
    "submission = pd.DataFrame({\n",
    "    \"image_id\":[os.path.basename(p) for p in test_ds.file_paths],\n",
    "    \"label\":[names[i] for i in preds]\n",
    "})\n",
    "submission.to_csv(\"sample_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
